{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp convolutions_pooling_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecuturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecuturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecuturesFromScratch.training_loop_03 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = get_datasets()\n",
    "m, o, lf = get_model(0.1)\n",
    "fit(3, m, o, lf, train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Reshape(Module):\n",
    "    def __init__(self, channels, size1, size2):\n",
    "        super().__init__()\n",
    "        self.size1 = size1\n",
    "        self.size2 = size2\n",
    "        self.channels = channels\n",
    "    \n",
    "    def forward(self, xb): return xb.view(-1, self.channels, self.size1, self.size2)\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = out.g.reshape(-1, self.channels*self.size1*self.size2)\n",
    "    \n",
    "    def __repr__(self): return f'Reshape({self.channels}, {self.size1}, {self.size2})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Flatten(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.size1 = xb.shape[2]\n",
    "        self.size2 = xb.shape[3]\n",
    "        self.channels = xb.shape[1]\n",
    "        return xb.view(xb.shape[0],-1)\n",
    "    \n",
    "    def bwd(self, out, inp): inp.g = out.g.view(-1, self.channels, self.size1, self.size2)\n",
    "        \n",
    "    def __repr__(self): return f'Flatten()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_fan(dim1, dim2, dim3, dim4, fan_out):\n",
    "    if dim3 == None and dim4 == None: return dim1\n",
    "    else:\n",
    "        rec_fs = dim3*dim4\n",
    "        return dim2*rec_fs if fan_out else dim1*rec_fs\n",
    "    \n",
    "def get_gain(leak): return math.sqrt(2.0 / (1 + leak**2))\n",
    "    \n",
    "def get_weight(dim1, dim2, dim3 = None, dim4 = None, leak=1., fan_out=False):\n",
    "    fan = get_fan(dim1, dim2, dim3, dim4, fan_out)\n",
    "    gain = get_gain(leak)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    if dim3 == None and dim4 == None: return torch.randn(dim1, dim2) * std\n",
    "    else: return torch.randn(dim1, dim2, dim3, dim4) * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "test_conv = nn.Conv2d(1, 8, 5)\n",
    "xt, _, _, _ = get_mnist()\n",
    "xt = xt.view(-1, 1, 28, 28)\n",
    "test_conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(test_conv(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv.weight = nn.Parameter(get_weight(8, 1, 5, 5, 0, True)) \n",
    "get_stats(relu(test_conv(xt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(test_conv.weight, a=0.)\n",
    "get_stats(relu((test_conv(xt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Padding():\n",
    "    def __init__(self, size=1, mode=\"constant\", value=0):\n",
    "        self.size, self.mode, self.value = size, mode, value\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        if self.mode == \"constant\": return torch.nn.functional.pad(tensor, [self.size,self.size,self.size,self.size], value=self.value)\n",
    "    \n",
    "    def __repr__(self): return f'Padding (Mode: {self.mode}, Size: {self.size}, Value: {self.value})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(10, 16, 28, 28)\n",
    "bs = weight.shape[0]\n",
    "im_h = im_w = weight.shape[2]\n",
    "w_dim = weight.shape[1]\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "pad_amount = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dim = 4\n",
    "f_w = 6\n",
    "f_h = f_w\n",
    "test_conv = nn.Conv2d(w_dim, f_dim, f_w, padding=pad_amount, stride=stride)\n",
    "f = test_conv.weight\n",
    "test_conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = test_conv.bias\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_res = test_conv(weight)\n",
    "pt_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convolve(weight, filts, filts_bias, stride=1,padding=None):\n",
    "    n_filt, depth_f, f_w, f_h = filts.shape\n",
    "    bs, depth_im, im_w, im_h = weight.shape\n",
    "    \n",
    "    if padding is not None: \n",
    "        weight = padding(weight)\n",
    "        p_s = padding.size\n",
    "    else: p_s = 0\n",
    "        \n",
    "    _,_,p_w, p_h = weight.shape\n",
    "    \n",
    "    assert depth_f == depth_im\n",
    "\n",
    "    final = torch.zeros(bs, n_filt, int((im_w + 2*p_s - f_w)/stride)+1, int((im_h + 2*p_s - f_h)/stride)+1)\n",
    "    for j in range(0, p_w-f_h+1, stride): #vertical passes\n",
    "        for k in range(0, p_h-f_w+1, stride): #horizontal passes\n",
    "            final[:,:,j//stride,k//stride] = (weight[:,:,j:j+f_h,k:k+f_w].unsqueeze(1)*filts).sum(dim=-1).sum(dim=-1).sum(dim=-1) + filts_bias.unsqueeze(0)\n",
    "                \n",
    "    return final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = Padding(size=pad_amount)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = convolve(weight, f, b, stride, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(res, pt_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_back(out,inp,weight,bias,stride=1,padding=None):\n",
    "    dZ = out.g\n",
    "\n",
    "    (A_prev, W, b, stride) = inp, weight.d, bias.d, stride\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_C_prev, n_W_prev, n_H_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (n_C, n_C_prev, f, f) = W.shape\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_C, n_W, n_H) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = torch.zeros((m, n_C_prev, n_W_prev, n_H_prev))                           \n",
    "    dW = torch.zeros((n_C, n_C_prev, f, f))\n",
    "    db = torch.zeros((n_C, 1, 1, 1))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    if padding is not None: \n",
    "        A_prev = padding(A_prev)\n",
    "        dA_prev = padding(dA_prev)\n",
    "        \n",
    "    for h in range(n_H): # loop over vertical axis of the output volume\n",
    "        for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                \n",
    "                # Find the corners of the current \"slice\"\n",
    "                vert_start = h*stride\n",
    "                vert_end = vert_start + f\n",
    "                horiz_start = w*stride\n",
    "                horiz_end = horiz_start + f\n",
    "                    \n",
    "                # Use the corners to define the slice from a_prev_pad\n",
    "                a_slice = A_prev[:, :, horiz_start:horiz_end, vert_start:vert_end]\n",
    "                \n",
    "                ezdz = dZ[:, :, w, h].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "                # Update gradients for the filter, bias and input\n",
    "                dA_prev[:, :, horiz_start:horiz_end, vert_start:vert_end] += (W * ezdz).sum(dim=1)\n",
    "                dW += (a_slice.unsqueeze(1)*ezdz).sum(dim=0)\n",
    "                db += dZ[:, :, w, h].sum(dim=0).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "                \n",
    "    if padding is not None: dA_prev = dA_prev[:, :, padding.size:-padding.size, padding.size:-padding.size]\n",
    "    \n",
    "    weight.update(dW)\n",
    "    bias.update(db.view(-1))\n",
    "    inp.g = dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Conv(Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, leak=1, padding=None):\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_out = n_in, n_out\n",
    "        self.filters = Parameter(get_weight(n_out, n_in, kernel_size, kernel_size, leak, True))\n",
    "        self.bias = Parameter(torch.zeros(n_out))\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, xb): return convolve(xb, self.filters.d, self.bias.d, self.stride, self.padding)\n",
    "    \n",
    "    def bwd(self, out, inp): conv_back(out, inp, self.filters,self.bias,self.stride,self.padding)\n",
    "        \n",
    "    def __repr__(self): return f'Conv({self.n_in}, {self.n_out}, ks = {self.kernel_size}, stride = {self.stride})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad1 = Padding(2)\n",
    "pad2 = Padding(3)\n",
    "\n",
    "def get_basic_conv_model(lr):\n",
    "    model = SequentialModel(Reshape(1, 28, 28), \n",
    "                            Conv(1, 16, 5, stride=3, leak=0, padding=pad1), \n",
    "                            ReLU(), \n",
    "                            Conv(16, 8, 5, stride=2, leak=1, padding=pad2), \n",
    "                            Flatten(), \n",
    "                            Linear(288, 10, False))\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, o, l = get_basic_conv_model(0.1)\n",
    "loss_func = l\n",
    "xt, yt, _, _ = get_mnist()\n",
    "sx, sy = xt[:100], yt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx), sy)\n",
    "loss_func.backward()\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxg = sx.g.clone()\n",
    "cw1g = m.layers[1].filters.grad.clone()\n",
    "cb1g = m.layers[1].bias.grad.clone()\n",
    "cw2g = m.layers[3].filters.grad.clone()\n",
    "cb2g = m.layers[3].bias.grad.clone()\n",
    "lw = m.layers[5].w.grad.clone()\n",
    "lb = m.layers[5].b.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx2 = sx.clone().requires_grad_(True)\n",
    "m.layers[1].filters.d.requires_grad_(True)\n",
    "m.layers[1].bias.d.requires_grad_(True)\n",
    "m.layers[3].filters.d.requires_grad_(True)\n",
    "m.layers[3].bias.d.requires_grad_(True)\n",
    "m.layers[5].w.d.requires_grad_(True)\n",
    "m.layers[5].b.d.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx2), sy)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(lb, m.layers[5].b.d.grad)\n",
    "test_near(lw, m.layers[5].w.d.grad)\n",
    "test_near(cb2g, m.layers[3].bias.d.grad)\n",
    "test_near(cw2g, m.layers[3].filters.d.grad)\n",
    "test_near(cb1g, m.layers[1].bias.d.grad)\n",
    "test_near(cw1g, m.layers[1].filters.d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_linear_model(lr):\n",
    "    model = SequentialModel(Linear(784, 50, True), ReLU(), Linear(50, 10, False))\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func\n",
    "\n",
    "def get_model(lr, modules):\n",
    "    model = SequentialModel(*modules)\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [Reshape(1, 28, 28), \n",
    "     Conv(1, 4, 5, stride=1, leak=0), \n",
    "     ReLU(), \n",
    "     Conv(4, 1, 5, stride=1, leak=1), \n",
    "     Flatten(), \n",
    "     Linear(20*20, 10, False)]\n",
    "\n",
    "m, o, l = get_model(0.1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_small_datasets():\n",
    "    xt, yt, xv, yv = get_mnist()\n",
    "    tr = Dataset(xt[:500], yt[:500])\n",
    "    val = Dataset(xv[:100], yv[:100])\n",
    "    train = DataLoader(tr, Batcher(tr, 64, True), collate)\n",
    "    valid = DataLoader(val, Batcher(val, 64, False), collate)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid = get_small_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(3, m, o, l, train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def max_pool(inp): return inp.max(dim=-1).values.max(dim=-1).values\n",
    "def avg_pool(inp): return torch.mean(inp,dim=(2,3))\n",
    "\n",
    "def pool(inp, ks, stride, padding=None, operation=max_pool):\n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inpp = padding(inp)\n",
    "    else: inpp = inp\n",
    "        \n",
    "    bs, nc, h, w = inp.shape\n",
    "    nw, nh = int((int(w - ks) / stride)+1), int((int(h - ks) / stride)+1)\n",
    "    \n",
    "    out = torch.zeros(bs, nc, nw, nh)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            window = inpp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "            out[:,:,j,i] = operation(window)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = torch.randn(16, 3, 28, 28)\n",
    "ks = 3\n",
    "stride = 1\n",
    "pad_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_max = nn.MaxPool2d(ks, stride=stride, padding=pad_size)\n",
    "py_avg = nn.AvgPool2d(ks, stride=stride, padding=pad_size)\n",
    "py_max_result = py_max(test_t)\n",
    "py_avg_result = py_avg(test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = Padding(size=pad_size) if pad_size > 0 else None\n",
    "my_avg = pool(test_t, ks, stride, pad, avg_pool)\n",
    "my_max = pool(test_t, ks, stride, pad, max_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(py_max_result, my_max)\n",
    "test_near(py_avg_result, my_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def max_back(window): \n",
    "    A = torch.zeros(window.shape)\n",
    "    bs, nc, _, _ = window.shape\n",
    "    \n",
    "    for i in range(bs):\n",
    "        for j in range(nc):\n",
    "            A[i,j,:,:] = window[i,j,:,:] == window[i,j,:,:].max()\n",
    "    \n",
    "    return A\n",
    "    \n",
    "    \n",
    "def average_back(window, shape):\n",
    "    height, width = shape\n",
    "    window_sum = window.unsqueeze(-1).unsqueeze(-1) / height*width\n",
    "    return torch.ones(shape).unsqueeze(0).unsqueeze(0) * window_sum\n",
    "\n",
    "def pool_back(out, inp, ks, stride, padding=None, operation=max_pool):\n",
    "    dZ = out.g\n",
    "    \n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inp = padding(inp)\n",
    "        \n",
    "    bs, nc, nh, nw = dZ.shape\n",
    "\n",
    "    dA_prev = torch.zeros(inp.shape)\n",
    "    \n",
    "    shape = (ks,ks)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            \n",
    "            if operation == max_pool:\n",
    "                window = inp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "                \n",
    "                mask = max_back(window)\n",
    "                \n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += mask*dZ[:,:,j,i].unsqueeze(-1).unsqueeze(-1)\n",
    "            \n",
    "            elif operation == avg_pool:\n",
    "                dz = dZ[:,:,j, i]\n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += average_back(dz, shape)\n",
    "    \n",
    "    inp.g = dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pool(Module):\n",
    "    def __init__(self, operation, ks=2, stride=2, padding=None):\n",
    "        super().__init__()\n",
    "        self.ks, self.stride, self.padding, self.operation = ks, stride, padding, operation\n",
    "    \n",
    "    def forward(self, xb): return pool(xb, self.ks, self.stride, self.padding, operation=self.operation)\n",
    "    \n",
    "    def bwd(self, out, inp): return pool_back(out, inp, self.ks, self.stride, self.padding, operation=self.operation)\n",
    "    \n",
    "    def __repr__(self): \n",
    "        if self.operation == max_pool: ptype = \"Max\"\n",
    "        elif self.operation == avg_pool: ptype = \"Average\"\n",
    "        else: ptype = \"Custom\"\n",
    "        return f'{ptype}Pool(ks: {self.ks}, stride: {self.stride})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Reshape(1, 28, 28),\n",
    "          Conv(1, 4),\n",
    "          Pool(avg_pool, ks=2, stride=1),\n",
    "          Conv(4, 1),\n",
    "          Flatten(),\n",
    "          Linear(529, 10, False)]\n",
    "m, o, l = get_model(0.1, layers)\n",
    "train,valid = get_small_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx), sy)\n",
    "loss_func.backward()\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxg = sx.g.clone()\n",
    "cw = m.layers[1].filters.grad.clone()\n",
    "cb = m.layers[1].bias.grad.clone()\n",
    "lw = m.layers[5].w.grad.clone()\n",
    "lb = m.layers[5].b.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx2 = sx.clone().requires_grad_(True)\n",
    "m.layers[1].filters.d.requires_grad_(True)\n",
    "m.layers[1].bias.d.requires_grad_(True)\n",
    "m.layers[5].w.d.requires_grad_(True)\n",
    "m.layers[5].b.d.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx2), sy)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.layers[1].filters.d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(sxg, sx2.grad)\n",
    "test_near(cw, m.layers[1].filters.d.grad)\n",
    "test_near(cb, m.layers[1].bias.d.grad)\n",
    "test_near(lw, m.layers[5].w.d.grad)\n",
    "test_near(lb, m.layers[5].b.d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
