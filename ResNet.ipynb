{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp resnet_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecturesFromScratch.model_training_03 import *\n",
    "from ModernArchitecturesFromScratch.convolutions_pooling_04 import *\n",
    "from ModernArchitecturesFromScratch.callbacks_05 import *\n",
    "from ModernArchitecturesFromScratch.batchnorm_06 import *\n",
    "from ModernArchitecturesFromScratch.optimizers_07 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet \n",
    "> Fully implemented ResNet architecture from scratch: https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_runner(model=None, layers=None, lf=None, callbacks=[Stats([accuracy]), ProgressCallback(), HyperRecorder(['lr'])], opt=None, db=None):\n",
    "    \"Helper function to get a quick runner\"\n",
    "    if model is None:\n",
    "        model = SequentialModel(*layers) if layers is not None else get_linear_model(0.1)[0]\n",
    "    lf = CrossEntropy() if lf is None else lf\n",
    "    db = db if db is not None else get_mnist_databunch()\n",
    "    opt = opt if opt is not None else adam_opt()\n",
    "    learn = Learner(model,lf,opt,db)\n",
    "    return Runner(learn, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to make new classes that allow architectures that aren't straight forward passes through a defined set of layers. This is normally handled in the forward passes of pytorch with autograd. We need to be a bit more clever due to the fact that we need to define our gradients in each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NestedModel(Module):\n",
    "    \"NestModel that allows for a sequential model to be called withing an outer model\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,xb): return self.layers(xb)\n",
    "    \n",
    "    def bwd(self, out, inp): self.layers.backward()\n",
    "        \n",
    "    def parameters(self):\n",
    "        for p in self.layers.parameters(): yield p   \n",
    "    \n",
    "    def __repr__(self): return f'\\nSubModel( \\n{self.layers}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TestMixingGrads(NestedModel):\n",
    "    \"Test module to see if nested SequentialModels will work\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = SequentialModel(Linear(784, 50, True), ReLU(), Linear(50,25, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the gradients and the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): \n",
       "SubModel( \n",
       "(Layer1): Linear(784, 50)\n",
       "(Layer2): ReLU()\n",
       "(Layer3): Linear(50, 25)\n",
       ")\n",
       "(Layer2): Linear(25, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = SequentialModel(TestMixingGrads(), Linear(25,10, False))\n",
    "db = get_mnist_databunch()\n",
    "lf = CrossEntropy()\n",
    "optimizer = adam_opt()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(m, CrossEntropy(), Optimizer, db)\n",
    "run = Runner(learn, [CheckGrad()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "run.fit(1,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored Conv Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start making ResNets, we first define a few helper modules that abstract some of the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AutoConv(Conv):\n",
    "    \"Automatic resizing of padding based on kernel size to ensure constant dimensions of input to output\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1):\n",
    "        padding = Padding(kernel_size // 2)\n",
    "        super().__init__(n_in, n_out, kernel_size, stride, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvBatch(NestedModel):\n",
    "    \"Performs conv then batchnorm\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, **kwargs):\n",
    "        self.layers = SequentialModel(AutoConv(n_in, n_out, kernel_size, stride), \n",
    "                       Batchnorm(n_out))\n",
    "    \n",
    "    def __repr__(self): return f'{self.layers.layers[0]}, {self.layers.layers[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Identity(Module):\n",
    "    \"Module to perform the identity connection (what goes in, comes out)\"\n",
    "    def forward(self,xb): return xb\n",
    "    def bwd(self,out,inp): inp.g += out.g\n",
    "    def __repr__(self): return f'Identity Connection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final built up ResNet blocks that implement the skip connecton layers characteristic of a ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BasicRes(Module):\n",
    "    \"Basic block to implement the two different ResBlocks presented in the paper\"\n",
    "    def __init__(self, n_in, n_out, expansion=1, stride=1, Activation=ReLU, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_out, self.expansion, self.stride, self.Activation = n_in, n_out, expansion, stride, Activation\n",
    "        \n",
    "        self.identity = Identity() if self.do_identity else AutoConv(self.n_in, self.get_expansion, kernel_size=1, stride=2)\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.id_out = self.identity(xb)\n",
    "        self.res_out = self.res_blocks(xb)\n",
    "        self.out = self.id_out + self.res_out\n",
    "        return self.out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        self.res_out.g = out.g\n",
    "        self.id_out.g = out.g\n",
    "        self.res_blocks.backward()\n",
    "        self.identity.backward()\n",
    "    \n",
    "    @property\n",
    "    def get_expansion(self): return self.n_out * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def do_identity(self): return self.n_in == self.n_out\n",
    "    \n",
    "    def parameters(self): \n",
    "        layers = [self.res_blocks, self.identity]\n",
    "        for m in layers: \n",
    "            for p in m.parameters(): yield p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BasicResBlock(BasicRes):\n",
    "    expansion=1\n",
    "    \"Basic ResBlock layer, 2 `ConvBatch` layers with no expansion\"\n",
    "    def __init__(self, n_in, n_out, *args, **kwargs):\n",
    "        super().__init__(n_in, n_out, *args, **kwargs)\n",
    "        expansion = 1\n",
    "        \n",
    "        self.res_blocks = SequentialModel(\n",
    "            ConvBatch(n_in, n_out, stride=self.stride),\n",
    "            self.Activation(),\n",
    "            ConvBatch(n_out, self.n_out*expansion)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BottleneckBlock(BasicRes):\n",
    "    expansion=4\n",
    "    \"Bottleneck layer, 3 `ConvBatch` layers with an expansion factor of 4\"\n",
    "    def __init__(self, n_in, n_out, *args, **kwargs):\n",
    "        super().__init__(n_in, n_out, *args, **kwargs)\n",
    "        \n",
    "        self.res_blocks = SequentialModel(\n",
    "            ConvBatch(n_in, n_out, kernel_size=1, stride=1),\n",
    "            self.Activation(),\n",
    "            ConvBatch(n_out, n_out),\n",
    "            self.Activation(),\n",
    "            ConvBatch(n_out, self.expansion, kernel_size=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(NestedModel):\n",
    "    \"Adds the final activation after the skip connection addition\"\n",
    "    def __init__(self, n_in, n_out, block=BasicResBlock, stride=1, kernel_size=3, Activation=ReLU, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_out, self.exp, self.ks, self.stride = n_in, n_out, block.expansion, kernel_size, stride\n",
    "        self.layers = SequentialModel(block(n_in=n_in, n_out=n_out, expansion=block.expansion, kernel_size=kernel_size, stride=stride, Activation=Activation,**kwargs), \n",
    "                                      Activation())\n",
    "    \n",
    "    def __repr__(self): return f'ResBlock({self.n_in}, {self.n_out*self.exp}, kernel_size={self.ks}, stride={self.stride})'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResLayer(NestedModel):\n",
    "    \"Sequential ResBlock layers as outlined in the paper\"\n",
    "    def __init__(self, block, n, n_in, n_out, *args, **kwargs):\n",
    "        layers = []\n",
    "        self.block, self.n, self.n_in, self.n_out = block, n, n_in, n_out\n",
    "        \n",
    "        downsampling = 2 if n_in != n_out else 1\n",
    "\n",
    "        layers = [ResBlock(n_in, n_out, block, stride=downsampling),\n",
    "        *[ResBlock(n_out * block.expansion, n_out, block, stride=1) for i in range(n-1)]]\n",
    "        \n",
    "        self.layers = SequentialModel(*layers)\n",
    "    \n",
    "    def __repr__(self): return f'ResLayer(\\n{self.layers}\\n)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ResLayer(NestedModel):\n",
    "    \"Sequential res layers\"\n",
    "    def __init__(self, block, n, n_in, n_out, *args, **kwargs):\n",
    "        layers = []\n",
    "        self.block, self.n, self.n_in, self.n_out = block, n, n_in, n_out\n",
    "        \n",
    "        downsampling = 2 if n_in != n_out else 1\n",
    "\n",
    "        layers = [ResBlock(n_in, n_out, block, stride=downsampling),\n",
    "        *[ResBlock(n_out * block.expansion, n_out, block, stride=1) for i in range(n-1)]]\n",
    "        \n",
    "        self.layers = SequentialModel(*layers)\n",
    "    \n",
    "    def __repr__(self): return f'ResLayer(\\n{self.layers}\\n)'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet(NestedModel):\n",
    "    \"Class to create ResNet architectures of dynamic sizing\"\n",
    "    def __init__(self, block, layer_sizes=[64, 128, 256, 512], depths=[2,2,2,2], c_in=3, \n",
    "               c_out=1000, im_size=(28,28), activation=ReLU, *args, **kwargs):\n",
    "        \n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        gate = [\n",
    "            Reshape(c_in, im_size[0], im_size[1]),\n",
    "            ConvBatch(c_in, self.layer_sizes[0], stride=2, kernel_size=7),\n",
    "            activation(),\n",
    "            Pool(max_pool, ks=3, stride=2, padding=Padding(1))\n",
    "        ]\n",
    "        \n",
    "        self.conv_sizes = list(zip(self.layer_sizes, self.layer_sizes[1:]))\n",
    "        body = [\n",
    "            ResLayer(block, depths[0], self.layer_sizes[0], self.layer_sizes[0], Activation=activation, *args, **kwargs),\n",
    "            *[ResLayer(block, n, n_in * block.expansion, n_out, Activation=activation)\n",
    "             for (n_in,n_out), n in zip(self.conv_sizes, depths[1:])]\n",
    "        ]\n",
    "        \n",
    "        tail = [\n",
    "            Pool(avg_pool, ks=1, stride=1, padding=None),\n",
    "            Flatten(),\n",
    "            Linear(self.layer_sizes[-1]*block.expansion, c_out, relu_after=False)\n",
    "        ]\n",
    "\n",
    "        self.layers = SequentialModel(\n",
    "            *[layer for layer in gate],\n",
    "            *[layer for layer in body],\n",
    "            *[layer for layer in tail]\n",
    "        )\n",
    "    \n",
    "    def __repr__(self): return f'ResNet: \\n{self.layers}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ResNet(NestedModel):\n",
    "    \"Class to create ResNet architectures of dynamic sizing\"\n",
    "    def __init__(self, block, layer_sizes=[64, 128, 256, 512], depths=[2,2,2,2], c_in=3, \n",
    "               c_out=1000, im_size=(28,28), activation=ReLU, *args, **kwargs):\n",
    "        \n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        gate = [\n",
    "            Reshape(c_in, im_size[0], im_size[1]),\n",
    "            ConvBatch(c_in, self.layer_sizes[0], stride=2, kernel_size=7),\n",
    "            activation(),\n",
    "            Pool(max_pool, ks=3, stride=2, padding=Padding(1))\n",
    "        ]\n",
    "        \n",
    "        self.conv_sizes = list(zip(self.layer_sizes, self.layer_sizes[1:]))\n",
    "        body = [\n",
    "            ResLayer(block, depths[0], self.layer_sizes[0], self.layer_sizes[0], Activation=activation, *args, **kwargs),\n",
    "            *[ResLayer(block, n, n_in * block.expansion, n_out, Activation=activation)\n",
    "             for (n_in,n_out), n in zip(self.conv_sizes, depths[1:])]\n",
    "        ]\n",
    "        \n",
    "        tail = [\n",
    "            Pool(avg_pool, ks=1, stride=1, padding=None),\n",
    "            Flatten(),\n",
    "            Linear(self.layer_sizes[-1]*block.expansion, c_out, relu_after=False)\n",
    "        ]\n",
    "\n",
    "        self.layers = SequentialModel(\n",
    "            *[layer for layer in gate],\n",
    "            *[layer for layer in body],\n",
    "            *[layer for layer in tail]\n",
    "        )\n",
    "    \n",
    "    def __repr__(self): return f'ResNet: \\n{self.layers}'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(3, 28, 28)\n",
       "(Layer2): Conv(3, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(64, 128, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(128, 128, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(128, 256, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(512, 1000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ResNet(BasicResBlock)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def GetResnet(size, c_in=3, c_out=10, *args, **kwargs):\n",
    "    \"Helper function to get ResNet architectures of different sizes\"\n",
    "    if size == 18: return ResNet(c_in=c_in, c_out=c_out, block=BasicResBlock, depths=[2, 2, 2, 2], size=size, **kwargs)\n",
    "    elif size == 34: return ResNet(c_in=c_in, c_out=c_out, block=BasicResBlock, depths=[3, 4, 6, 3], size=size, **kwargs)\n",
    "    elif size == 50: return ResNet(c_in=c_in, c_out=c_out, block=BottleneckBlock, depths=[3, 4, 6, 3], size=size, **kwargs)\n",
    "    elif size == 150: return ResNet(c_in=c_in, c_out=c_out, block=BottleneckBlock, depths=[3, 4, 23, 3], size=size, **kwargs)\n",
    "    elif size == 152: return ResNet(c_in=c_in, c_out=c_out, block=BottleneckBlock, depths=[3, 8, 36, 3], size=size, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out the ResNet Architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(64, 128, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(128, 128, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(128, 256, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(512, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(18, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(64, 64, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(64, 128, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(128, 128, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(128, 128, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(128, 128, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(128, 256, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer5): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer6): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(512, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(34, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 256, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(512, 1024, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer5): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer6): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(1024, 2048, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(50, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 256, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(512, 1024, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer5): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer6): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer7): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer8): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer9): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer10): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer11): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer12): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer13): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer14): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer15): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer16): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer17): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer18): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer19): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer20): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer21): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer22): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer23): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(1024, 2048, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(150, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet: \n",
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 64, ks = 7, stride = 2), Batchnorm\n",
       "(Layer3): ReLU()\n",
       "(Layer4): MaxPool(ks: 3, stride: 2)\n",
       "(Layer5): ResLayer(\n",
       "(Layer1): ResBlock(64, 256, kernel_size=3, stride=1)\n",
       "(Layer2): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(256, 256, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer6): ResLayer(\n",
       "(Layer1): ResBlock(256, 512, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer5): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer6): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer7): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       "(Layer8): ResBlock(512, 512, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer7): ResLayer(\n",
       "(Layer1): ResBlock(512, 1024, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer4): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer5): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer6): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer7): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer8): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer9): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer10): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer11): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer12): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer13): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer14): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer15): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer16): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer17): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer18): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer19): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer20): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer21): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer22): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer23): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer24): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer25): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer26): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer27): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer28): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer29): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer30): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer31): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer32): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer33): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer34): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer35): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       "(Layer36): ResBlock(1024, 1024, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer8): ResLayer(\n",
       "(Layer1): ResBlock(1024, 2048, kernel_size=3, stride=2)\n",
       "(Layer2): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       "(Layer3): ResBlock(2048, 2048, kernel_size=3, stride=1)\n",
       ")\n",
       "(Layer9): AveragePool(ks: 1, stride: 1)\n",
       "(Layer10): Flatten()\n",
       "(Layer11): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(152, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = get_runner(model=GetResnet(18,c_in=1, c_out=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
