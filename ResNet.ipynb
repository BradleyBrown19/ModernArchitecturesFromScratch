{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp resnet_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecturesFromScratch.model_training_03 import *\n",
    "from ModernArchitecturesFromScratch.convolutions_pooling_04 import *\n",
    "from ModernArchitecturesFromScratch.callbacks_05 import *\n",
    "from ModernArchitecturesFromScratch.batchnorm_06 import *\n",
    "from ModernArchitecturesFromScratch.optimizers_07 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet \n",
    "> Fully implemented ResNet architecture from scratch: https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_runner(model=None, layers=None, lf=None, callbacks=[Stats([accuracy]), ProgressCallback(), HyperRecorder(['lr'])], opt=None, db=None):\n",
    "    \"Helper function to get a quick runner\"\n",
    "    if model is None:\n",
    "        model = SequentialModel(*layers) if layers is not None else get_linear_model(0.1)[0]\n",
    "    lf = CrossEntropy() if lf is None else lf\n",
    "    db = db if db is not None else get_mnist_databunch()\n",
    "    opt = opt if opt is not None else adam_opt()\n",
    "    learn = Learner(model,lf,opt,db)\n",
    "    return Runner(learn, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to make new classes that allow architectures that aren't straight forward passes through a defined set of layers. This is normally handled in the forward passes of pytorch with autograd. We need to be a bit more clever due to the fact that we need to define our gradients in each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NestedModel(Module):\n",
    "    \"NestModel that allows for a sequential model to be called withing an outer model\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,xb): return self.layers(xb)\n",
    "    \n",
    "    def bwd(self, out, inp): self.layers.backward()\n",
    "        \n",
    "    def parameters(self):\n",
    "        for p in self.layers.parameters(): yield p   \n",
    "    \n",
    "    def __repr__(self): return f'\\nSubModel( \\n{self.layers}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TestMixingGrads(NestedModel):\n",
    "    \"Test Module so Nested SequentialModels will work\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = SequentialModel(Linear(784, 50, True), ReLU(), Linear(50,25, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the gradients and the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): \n",
       "SubModel( \n",
       "(Layer1): Linear(784, 50)\n",
       "(Layer2): ReLU()\n",
       "(Layer3): Linear(50, 25)\n",
       ")\n",
       "(Layer2): Linear(25, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = SequentialModel(TestMixingGrads(), Linear(25,10, False))\n",
    "db = get_mnist_databunch()\n",
    "lf = CrossEntropy()\n",
    "optimizer = adam_opt()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(m, CrossEntropy(), Optimizer, db)\n",
    "run = Runner(learn, [CheckGrad()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "run.fit(1,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start making ResNets, we first define a few helper modules that abstract some of the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AutoConv(Conv):\n",
    "    \"Automatic resizing of padding based on kernel size to ensure constant dimensions of input to output\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1):\n",
    "        padding = Padding(kernel_size // 2)\n",
    "        super().__init__(n_in, n_out, kernel_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvBatch(NestedModel):\n",
    "    \"Performs conv then batchnorm\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, **kwargs):\n",
    "        self.layers = SequentialModel(AutoConv(n_in, n_out, kernel_size, stride), \n",
    "                       Batchnorm(n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvLayer(NestedModel):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, leak=1, Activation=ReLU):\n",
    "        \"Implements conv, batchnorm, relu pass\"\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_out = n_in, n_out\n",
    "        self.layers = SequentialModel(ConvBatch(n_in, n_out, kernel_size, stride),\n",
    "                           Activation())\n",
    "        \n",
    "    def __repr__(self): return f'ConvBnActivation({self.n_in}, {self.n_out})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Identity(Module):\n",
    "    \"Module to perform the identity connection (what goes in, comes out)\"\n",
    "    def forward(self,xb): return xb\n",
    "    def bwd(self,out,inp): inp.g += out.g\n",
    "    def __repr__(self): return f'Identity Connection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final built up ResNet blocks that implement the skip connecton layers characteristic of a ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseRes(Module):\n",
    "    \"Resblock Layer: ConvBnActivation layer with a skip connection between inputs and outputs, dynamically changes sizing\"\n",
    "    def __init__(self, expansion, n_in, n_h, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_in, n_out = n_in*expansion, n_h*expansion\n",
    "        \n",
    "        if expansion == 1: layers = [ConvLayer(n_in, n_h, 3, stride=stride), ConvLayer(n_h, n_out, 3, stride=stride)]\n",
    "        else: layers = [\n",
    "            ConvLayer(n_in, n_h, 1),\n",
    "            ConvLayer(n_h, n_h, 3, stride=stride),\n",
    "            ConvLayer(n_h, n_out, 1)\n",
    "        ]\n",
    "        \n",
    "        self.conv_layer = SequentialModel(*layers)\n",
    "        \n",
    "        self.identity = Identity() if n_in == n_out else SequentialModel(Pool('Average', ks=2), ConvLayer(n_in, n_out, kernel_size=1))\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.conv_out = self.conv_layer(xb)\n",
    "        self.id_out = self.identity(xb)\n",
    "        self.out = self.conv_out + self.id_out\n",
    "        return self.out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        self.conv_out.g = out.g\n",
    "        self.id_out.g = out.g\n",
    "        self.conv_layer.backward()\n",
    "        self.identity.backward()\n",
    "    \n",
    "    def parameters(self): \n",
    "        for p in self.conv_layer.parameters(): yield p \n",
    "    \n",
    "    def __repr__(self): return f'{self.conv_layer} || {self.identity}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class BaseRes(Module):\n",
    "    \"Resblock Layer: ConvBnActivation layer with a skip connection between inputs and outputs, dynamically changes sizing\"\n",
    "    def __init__(self, expansion, n_in, n_h, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_in, n_out = n_in*expansion, n_h*expansion\n",
    "        \n",
    "        if expansion == 1: layers = [ConvLayer(n_in, n_h, 3, stride=stride), ConvLayer(n_h, n_out, 3, stride=stride)]\n",
    "        else: layers = [\n",
    "            ConvLayer(n_in, n_h, 1),\n",
    "            ConvLayer(n_h, n_h, 3, stride=stride),\n",
    "            ConvLayer(n_h, n_out, 1)\n",
    "        ]\n",
    "        \n",
    "        self.conv_layer = SequentialModel(*layers)\n",
    "        \n",
    "        self.identity = Identity() if n_in == n_out else SequentialModel(Pool('Average', ks=2), ConvLayer(n_in, n_out, kernel_size=1))\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.conv_out = self.conv_layer(xb)\n",
    "        self.id_out = self.identity(xb)\n",
    "        self.out = self.conv_out + self.id_out\n",
    "        return self.out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        self.conv_out.g = out.g\n",
    "        self.id_out.g = out.g\n",
    "        self.conv_layer.backward()\n",
    "        self.identity.backward()\n",
    "    \n",
    "    def parameters(self): \n",
    "        for p in self.conv_layer.parameters(): yield p \n",
    "    \n",
    "    def __repr__(self): return f'{self.conv_layer} || {self.identity}'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(NestedModel):\n",
    "    \"Adds the final activation after the skip connection addition\"\n",
    "    def __init__(self, expansion, n_in, n_h, stride=1, kernel_size=3, Activation=ReLU, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_h, self.expansion = n_in, n_h, expansion\n",
    "        self.layers = SequentialModel(BaseRes(expansion, n_in, n_h, kernel_size=kernel_size, stride=stride, **kwargs), Activation())\n",
    "    \n",
    "    def __repr__(self): return f'ResBlock({self.n_in}, {self.n_h*self.expansion})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XResNet():\n",
    "    \"Class to create ResNet architectures of dynamic sizing\"\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000, size=[28,28]):\n",
    "        nfs = [c_in, (c_in+1)*8, 64, 64]\n",
    "        stem = [ConvLayer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        \n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        \n",
    "        res = SequentialModel(\n",
    "            Reshape(c_in, *size),\n",
    "            *stem,\n",
    "            Pool(max_pool, ks=3, stride=2, padding=Padding(1)),\n",
    "            *res_layers,\n",
    "            Pool(avg_pool,ks=1), Flatten(),\n",
    "            Linear(nfs[-1]*expansion, c_out, False),\n",
    "        )\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
    "        return NestedSequentialModel(*[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "              for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class XResNet():\n",
    "    \"Class to create ResNet architectures of dynamic sizing\"\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000, size=[28,28]):\n",
    "        nfs = [c_in, (c_in+1)*8, 64, 64]\n",
    "        stem = [ConvLayer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "            for i in range(3)]\n",
    "\n",
    "        nfs = [64//expansion,64,128,256,512]\n",
    "        \n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                      n_blocks=l, stride=1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        \n",
    "        res = SequentialModel(\n",
    "            Reshape(c_in, *size),\n",
    "            *stem,\n",
    "            Pool(max_pool, ks=3, stride=2, padding=Padding(1)),\n",
    "            *res_layers,\n",
    "            Pool(avg_pool,ks=1), Flatten(),\n",
    "            Linear(nfs[-1]*expansion, c_out, False),\n",
    "        )\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
    "        return NestedSequentialModel(*[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "              for i in range(n_blocks)])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NestedSequentialModel(SequentialModel):\n",
    "    def __repr__(self): return f'(\\n{super().__repr__()}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def GetResnet(size, **kwargs):\n",
    "    \"Helper function to get ResNet architectures of different sizes\"\n",
    "    if size == 18: return XResNet.create(1, [2,2,2,2], **kwargs)\n",
    "    elif size == 34: return XResNet.create(1, [3,4,6,3], **kwargs)\n",
    "    elif size == 50: return XResNet.create(4, [3,4,6,3], **kwargs)\n",
    "    elif size == 150: return XResNet.create(4, [3,4,23,3], **kwargs)\n",
    "    elif size == 152: return XResNet.create(4, [3,8,36,3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out the ResNet Architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): ConvBnActivation(1, 16)\n",
       "(Layer3): ConvBnActivation(16, 64)\n",
       "(Layer4): ConvBnActivation(64, 64)\n",
       "(Layer5): MaxPool(ks: 3, stride: 2)\n",
       "(Layer6): (\n",
       "(Layer1): ResBlock(64, 64)\n",
       "(Layer2): ResBlock(64, 64)\n",
       ")\n",
       "(Layer7): (\n",
       "(Layer1): ResBlock(64, 128)\n",
       "(Layer2): ResBlock(128, 128)\n",
       ")\n",
       "(Layer8): (\n",
       "(Layer1): ResBlock(128, 256)\n",
       "(Layer2): ResBlock(256, 256)\n",
       ")\n",
       "(Layer9): (\n",
       "(Layer1): ResBlock(256, 512)\n",
       "(Layer2): ResBlock(512, 512)\n",
       ")\n",
       "(Layer10): AveragePool(ks: 1, stride: 2)\n",
       "(Layer11): Flatten()\n",
       "(Layer12): Linear(512, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(18, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): ConvBnActivation(1, 16)\n",
       "(Layer3): ConvBnActivation(16, 64)\n",
       "(Layer4): ConvBnActivation(64, 64)\n",
       "(Layer5): MaxPool(ks: 3, stride: 2)\n",
       "(Layer6): (\n",
       "(Layer1): ResBlock(64, 64)\n",
       "(Layer2): ResBlock(64, 64)\n",
       "(Layer3): ResBlock(64, 64)\n",
       ")\n",
       "(Layer7): (\n",
       "(Layer1): ResBlock(64, 128)\n",
       "(Layer2): ResBlock(128, 128)\n",
       "(Layer3): ResBlock(128, 128)\n",
       "(Layer4): ResBlock(128, 128)\n",
       ")\n",
       "(Layer8): (\n",
       "(Layer1): ResBlock(128, 256)\n",
       "(Layer2): ResBlock(256, 256)\n",
       "(Layer3): ResBlock(256, 256)\n",
       "(Layer4): ResBlock(256, 256)\n",
       "(Layer5): ResBlock(256, 256)\n",
       "(Layer6): ResBlock(256, 256)\n",
       ")\n",
       "(Layer9): (\n",
       "(Layer1): ResBlock(256, 512)\n",
       "(Layer2): ResBlock(512, 512)\n",
       "(Layer3): ResBlock(512, 512)\n",
       ")\n",
       "(Layer10): AveragePool(ks: 1, stride: 2)\n",
       "(Layer11): Flatten()\n",
       "(Layer12): Linear(512, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(34, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): ConvBnActivation(1, 16)\n",
       "(Layer3): ConvBnActivation(16, 64)\n",
       "(Layer4): ConvBnActivation(64, 64)\n",
       "(Layer5): MaxPool(ks: 3, stride: 2)\n",
       "(Layer6): (\n",
       "(Layer1): ResBlock(16, 256)\n",
       "(Layer2): ResBlock(64, 256)\n",
       "(Layer3): ResBlock(64, 256)\n",
       ")\n",
       "(Layer7): (\n",
       "(Layer1): ResBlock(64, 512)\n",
       "(Layer2): ResBlock(128, 512)\n",
       "(Layer3): ResBlock(128, 512)\n",
       "(Layer4): ResBlock(128, 512)\n",
       ")\n",
       "(Layer8): (\n",
       "(Layer1): ResBlock(128, 1024)\n",
       "(Layer2): ResBlock(256, 1024)\n",
       "(Layer3): ResBlock(256, 1024)\n",
       "(Layer4): ResBlock(256, 1024)\n",
       "(Layer5): ResBlock(256, 1024)\n",
       "(Layer6): ResBlock(256, 1024)\n",
       ")\n",
       "(Layer9): (\n",
       "(Layer1): ResBlock(256, 2048)\n",
       "(Layer2): ResBlock(512, 2048)\n",
       "(Layer3): ResBlock(512, 2048)\n",
       ")\n",
       "(Layer10): AveragePool(ks: 1, stride: 2)\n",
       "(Layer11): Flatten()\n",
       "(Layer12): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(50, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): ConvBnActivation(1, 16)\n",
       "(Layer3): ConvBnActivation(16, 64)\n",
       "(Layer4): ConvBnActivation(64, 64)\n",
       "(Layer5): MaxPool(ks: 3, stride: 2)\n",
       "(Layer6): (\n",
       "(Layer1): ResBlock(16, 256)\n",
       "(Layer2): ResBlock(64, 256)\n",
       "(Layer3): ResBlock(64, 256)\n",
       ")\n",
       "(Layer7): (\n",
       "(Layer1): ResBlock(64, 512)\n",
       "(Layer2): ResBlock(128, 512)\n",
       "(Layer3): ResBlock(128, 512)\n",
       "(Layer4): ResBlock(128, 512)\n",
       ")\n",
       "(Layer8): (\n",
       "(Layer1): ResBlock(128, 1024)\n",
       "(Layer2): ResBlock(256, 1024)\n",
       "(Layer3): ResBlock(256, 1024)\n",
       "(Layer4): ResBlock(256, 1024)\n",
       "(Layer5): ResBlock(256, 1024)\n",
       "(Layer6): ResBlock(256, 1024)\n",
       "(Layer7): ResBlock(256, 1024)\n",
       "(Layer8): ResBlock(256, 1024)\n",
       "(Layer9): ResBlock(256, 1024)\n",
       "(Layer10): ResBlock(256, 1024)\n",
       "(Layer11): ResBlock(256, 1024)\n",
       "(Layer12): ResBlock(256, 1024)\n",
       "(Layer13): ResBlock(256, 1024)\n",
       "(Layer14): ResBlock(256, 1024)\n",
       "(Layer15): ResBlock(256, 1024)\n",
       "(Layer16): ResBlock(256, 1024)\n",
       "(Layer17): ResBlock(256, 1024)\n",
       "(Layer18): ResBlock(256, 1024)\n",
       "(Layer19): ResBlock(256, 1024)\n",
       "(Layer20): ResBlock(256, 1024)\n",
       "(Layer21): ResBlock(256, 1024)\n",
       "(Layer22): ResBlock(256, 1024)\n",
       "(Layer23): ResBlock(256, 1024)\n",
       ")\n",
       "(Layer9): (\n",
       "(Layer1): ResBlock(256, 2048)\n",
       "(Layer2): ResBlock(512, 2048)\n",
       "(Layer3): ResBlock(512, 2048)\n",
       ")\n",
       "(Layer10): AveragePool(ks: 1, stride: 2)\n",
       "(Layer11): Flatten()\n",
       "(Layer12): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(150, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): ConvBnActivation(1, 16)\n",
       "(Layer3): ConvBnActivation(16, 64)\n",
       "(Layer4): ConvBnActivation(64, 64)\n",
       "(Layer5): MaxPool(ks: 3, stride: 2)\n",
       "(Layer6): (\n",
       "(Layer1): ResBlock(16, 256)\n",
       "(Layer2): ResBlock(64, 256)\n",
       "(Layer3): ResBlock(64, 256)\n",
       ")\n",
       "(Layer7): (\n",
       "(Layer1): ResBlock(64, 512)\n",
       "(Layer2): ResBlock(128, 512)\n",
       "(Layer3): ResBlock(128, 512)\n",
       "(Layer4): ResBlock(128, 512)\n",
       "(Layer5): ResBlock(128, 512)\n",
       "(Layer6): ResBlock(128, 512)\n",
       "(Layer7): ResBlock(128, 512)\n",
       "(Layer8): ResBlock(128, 512)\n",
       ")\n",
       "(Layer8): (\n",
       "(Layer1): ResBlock(128, 1024)\n",
       "(Layer2): ResBlock(256, 1024)\n",
       "(Layer3): ResBlock(256, 1024)\n",
       "(Layer4): ResBlock(256, 1024)\n",
       "(Layer5): ResBlock(256, 1024)\n",
       "(Layer6): ResBlock(256, 1024)\n",
       "(Layer7): ResBlock(256, 1024)\n",
       "(Layer8): ResBlock(256, 1024)\n",
       "(Layer9): ResBlock(256, 1024)\n",
       "(Layer10): ResBlock(256, 1024)\n",
       "(Layer11): ResBlock(256, 1024)\n",
       "(Layer12): ResBlock(256, 1024)\n",
       "(Layer13): ResBlock(256, 1024)\n",
       "(Layer14): ResBlock(256, 1024)\n",
       "(Layer15): ResBlock(256, 1024)\n",
       "(Layer16): ResBlock(256, 1024)\n",
       "(Layer17): ResBlock(256, 1024)\n",
       "(Layer18): ResBlock(256, 1024)\n",
       "(Layer19): ResBlock(256, 1024)\n",
       "(Layer20): ResBlock(256, 1024)\n",
       "(Layer21): ResBlock(256, 1024)\n",
       "(Layer22): ResBlock(256, 1024)\n",
       "(Layer23): ResBlock(256, 1024)\n",
       "(Layer24): ResBlock(256, 1024)\n",
       "(Layer25): ResBlock(256, 1024)\n",
       "(Layer26): ResBlock(256, 1024)\n",
       "(Layer27): ResBlock(256, 1024)\n",
       "(Layer28): ResBlock(256, 1024)\n",
       "(Layer29): ResBlock(256, 1024)\n",
       "(Layer30): ResBlock(256, 1024)\n",
       "(Layer31): ResBlock(256, 1024)\n",
       "(Layer32): ResBlock(256, 1024)\n",
       "(Layer33): ResBlock(256, 1024)\n",
       "(Layer34): ResBlock(256, 1024)\n",
       "(Layer35): ResBlock(256, 1024)\n",
       "(Layer36): ResBlock(256, 1024)\n",
       ")\n",
       "(Layer9): (\n",
       "(Layer1): ResBlock(256, 2048)\n",
       "(Layer2): ResBlock(512, 2048)\n",
       "(Layer3): ResBlock(512, 2048)\n",
       ")\n",
       "(Layer10): AveragePool(ks: 1, stride: 2)\n",
       "(Layer11): Flatten()\n",
       "(Layer12): Linear(2048, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetResnet(152, c_in=1, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = get_runner(model=GetResnet(18,c_in=1, c_out=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
