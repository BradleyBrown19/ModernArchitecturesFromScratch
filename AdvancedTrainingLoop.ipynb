{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp advanced_training_loop_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecuturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecuturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecuturesFromScratch.training_loop_03 import *\n",
    "from ModernArchitecuturesFromScratch.convolutions_pooling_04 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __repr__(self): return f'X: {self.x.shape}, Y: {self.y.shape}'\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, batcher, collate_fcn): self.ds, self.batcher, self.collate_fcn = ds, batcher, collate_fcn    \n",
    "    def __iter__(self):\n",
    "        for b in self.batcher: yield self.collate_fcn([self.ds[i] for i in b])     \n",
    "    @property\n",
    "    def dataset(self): return self.ds\n",
    "    def __len__(self): return math.ceil(len(self.ds) / self.batcher.bs)\n",
    "    def __repr__(self): return f'Data: {self.ds}, bs = {self.batcher.bs}'\n",
    "    \n",
    "class Databunch():\n",
    "    def __init__(self, train_dl, valid_dl): self.train, self.valid = train_dl, valid_dl\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self): return self.train.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid.dataset\n",
    "    \n",
    "    def __repr__(self): return f'Databunch(\\nTrain: {self.train}, \\nValid{self.valid}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_databunch(xt, yt, xv, yv, bs=64):\n",
    "    t_data, v_data = Dataset(xt, yt), Dataset(xv, yv)\n",
    "    t_dl, v_dl = DataLoader(t_data, Batcher(t_data, bs, True), collate), DataLoader(t_data, Batcher(t_data, bs*2, False), collate)\n",
    "    return Databunch(t_dl, v_dl)\n",
    "\n",
    "def get_mnist_databunch():\n",
    "    return get_databunch(*get_mnist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_mnist_databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databunch(\n",
       "Train: Data: X: torch.Size([50000, 784]), Y: torch.Size([50000]), bs = 64, \n",
       "ValidData: X: torch.Size([50000, 784]), Y: torch.Size([50000]), bs = 128\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss_func, optimizer, db):\n",
    "        self.model, self.loss_func, self.optimizer, self.db = model, loss_func, optimizer, db\n",
    "    \n",
    "    def fit(self, epochs, lr):\n",
    "        opt = self.optimizer(self.model.parameters(), lr)\n",
    "        for epoch in range(epochs):\n",
    "            self.model.training = True\n",
    "            for xb, yb in self.db.train:\n",
    "                loss = self.loss_func(self.model(xb), yb)\n",
    "                self.loss_func.backward()\n",
    "                self.model.backward()\n",
    "\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "            self.model.training = False\n",
    "            acc, loss, epochs = 0,0,0\n",
    "            for xb, yb in self.db.valid:\n",
    "                pred = self.model(xb)\n",
    "                acc += accuracy(pred, yb)\n",
    "                loss += self.loss_func(pred, yb)\n",
    "                epochs += 1\n",
    "            acc /= epochs\n",
    "            loss /= epochs\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Accuracy: {acc}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [Linear(784, 50, True),\n",
    "           ReLU(),\n",
    "           Linear(50, 10, False)]\n",
    "m, _, loss_func = get_model(0, modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(m, loss_func, Optimizer, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.9447170495986938, Loss: 0.18049047887325287\n",
      "Epoch 2, Accuracy: 0.9536165595054626, Loss: 0.14963838458061218\n",
      "Epoch 3, Accuracy: 0.9769781231880188, Loss: 0.07752970606088638\n"
     ]
    }
   ],
   "source": [
    "learn.fit(3, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, learner, cbs=None):\n",
    "        cbs = [] if cbs is None else cbs\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "        \n",
    "        for cb in self.cbs:\n",
    "            cb.runner = self\n",
    "            \n",
    "        self.learner = learner\n",
    "    \n",
    "    @property\n",
    "    def model(self): return self.learner.model\n",
    "    @property\n",
    "    def optimizer(self): return self.learner.optimizer\n",
    "    @property\n",
    "    def loss_func(self): return self.learner.loss_func\n",
    "    @property\n",
    "    def databunch(self): return self.learner.db\n",
    "    \n",
    "    def do_one_batch(self, xb, yb):\n",
    "        self.xb, self.yb = xb, yb\n",
    "        \n",
    "        self.pred = self.learner.model(xb)\n",
    "        self.loss = self.learner.loss_func(self.pred, yb)\n",
    "        if self.check_callbacks('after_loss') or not self.learner.model.training: return\n",
    "        \n",
    "        self.learner.loss_func.backward()\n",
    "        if self.check_callbacks('after_loss_back'): return\n",
    "        \n",
    "        self.learner.model.backward()\n",
    "        if self.check_callbacks('after_model_back'): return\n",
    "        \n",
    "        self.opt.step()\n",
    "        if self.check_callbacks('after_opt'): return\n",
    "        \n",
    "        self.opt.zero_grad()\n",
    "        if self.check_callbacks('after_zero_grad'): return\n",
    "    \n",
    "    def do_all_batches(self, dl):\n",
    "        self.iters, self.iters_done = len(dl), 0\n",
    "        for xb, yb in dl:\n",
    "            if self.stop: break\n",
    "            if self.check_callbacks('before_batch'): return\n",
    "            self.do_one_batch(xb,yb)\n",
    "            if self.check_callbacks('after_batch'): return\n",
    "        self.iters = 0\n",
    "            \n",
    "        self.stop = False\n",
    "\n",
    "    def fit(self, epochs, lr=0.1):\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "        if self.check_callbacks('before_fit'): return\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.epoch = epoch\n",
    "            if self.check_callbacks('before_epoch'): return\n",
    "            if not self.check_callbacks('before_train'): self.do_all_batches(self.learner.db.train)\n",
    "            if not self.check_callbacks('before_valid'): self.do_all_batches(self.learner.db.valid)\n",
    "            if self.check_callbacks('after_epoch'): break\n",
    "        \n",
    "        if self.check_callbacks('after_fit'): return\n",
    "    \n",
    "    def check_callbacks(self, state):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, state, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callback():\n",
    "    _order = 0\n",
    "    def __getattr__(self,k):\n",
    "        #If callback doesn't have an attribute, check the runner\n",
    "        return getattr(self.runner, k)\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}'\n",
    "    \n",
    "class TrainEvalCallback(Callback):\n",
    "    _order = 10\n",
    "    \n",
    "    def before_fit(self):\n",
    "        self.runner.opt = self.learner.optimizer(self.learner.model.parameters(), self.lr)\n",
    "        self.runner.epochs_done = 0.\n",
    "        \n",
    "    def before_batch(self):\n",
    "        self.runner.iters_done += 1\n",
    "        self.runner.epochs_done += 1/self.iters\n",
    "        \n",
    "    def before_valid(self):\n",
    "        self.model.training = False\n",
    "    \n",
    "    def before_train(self):\n",
    "        self.model.training = True\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        self.runner.iters_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Stat():\n",
    "    def __init__(self, calc): self.calc, self.value, self.count = calc, 0., 0\n",
    "    \n",
    "    def __call__(self, bs, *args):\n",
    "        self.value += self.calc(*args) * bs\n",
    "        self.count += bs\n",
    "    \n",
    "    def reset(self): self.value, self.count = 0., 0\n",
    "        \n",
    "    def __repr__(self): return f'{(self.calc.__name__).capitalize()}: {self.value / self.count}' if self.count > 0 else f'{(self.calc.__name__).capitalize()}'\n",
    "    \n",
    "class StatTracker():\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.in_train = in_train\n",
    "        self.metrics = [Stat(m) for m in metrics]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.count, self.tot_loss = 0., 0.\n",
    "        for met in self.metrics: met.reset()\n",
    "    \n",
    "    def __len__(self): return len(self.metrics)\n",
    "    \n",
    "    def accumulate(self, run):\n",
    "        bs = run.xb.shape[0]\n",
    "        self.tot_loss = run.loss * bs\n",
    "        self.count += bs\n",
    "        for i,met in enumerate(self.metrics):\n",
    "            met(bs, run.pred, run.yb)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.count < 1: return \"\"\n",
    "        else:\n",
    "            printed_stats = f'Loss: {self.tot_loss / self.count}'\n",
    "            for met in self.metrics:\n",
    "                printed_stats += f', {met}'\n",
    "            return f'{\"Train\" if self.in_train else \"Valid\"}: {printed_stats}'\n",
    "    \n",
    "class Stats(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train, self.valid = StatTracker(metrics, True), StatTracker(metrics, False)\n",
    "    \n",
    "    def before_epoch(self):\n",
    "        self.train.reset()\n",
    "        self.valid.reset()\n",
    "    \n",
    "    def after_loss(self):\n",
    "        stats = self.train if self.model.training else self.valid\n",
    "        stats.accumulate(self.runner)\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        print(f'Epoch: {self.epoch+1}')\n",
    "        print(self.train)\n",
    "        print(self.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(learn, [Stats([accuracy])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
