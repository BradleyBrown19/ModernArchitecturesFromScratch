{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp fully_connected_network_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network\n",
    "> Implementing backward and forward passes to train a simple fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecturesFromScratch.basic_operations_01 import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near zero: 0.00012300178059376776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "xt,yt,xv,yv = get_mnist()\n",
    "\n",
    "n_out = (yt.max()+1).item()\n",
    "n_in = (xt[0].shape)[0]\n",
    "test_near_zero(xt.mean())\n",
    "show_im(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "#Kaiming initialization with fan_in\n",
    "def get_weight(in_d, out_d, relu_after):\n",
    "    \"Returns weight matrix of size `in_d` x `out_d` initialized using Kaiming initialization\"\n",
    "    if relu_after: return torch.randn(in_d, out_d) * math.sqrt(2. / in_d)\n",
    "    else: return torch.randn(in_d, out_d) / math.sqrt(in_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see: https://arxiv.org/abs/1502.01852 for more details and explanation on Kaiming initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1757,  0.2658, -0.8053,  0.5641, -0.9632],\n",
       "        [-0.6773,  0.5323,  1.2266, -1.5374, -0.1655],\n",
       "        [-0.0217, -1.1855,  0.1367,  1.1296,  0.1197],\n",
       "        [ 0.4580,  0.3639,  0.4997,  0.0106,  0.4932]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weight(4,5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export   \n",
    "#hide\n",
    "def linear(x, w, b): \n",
    "    \"Basic linear layer\"\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "def relu(x): \n",
    "    \"ReLU activation function\"\n",
    "    return x.clamp_min(0.) - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "def lin_rel(x, w, b): \n",
    "    \"Linear layer followed by ReLU activation on `x` with weight `w` and bias `b`\"\n",
    "    return relu(linear(x, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "def softmax(x): \n",
    "    \"Softmax activation function\"\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x.unsqueeze(-1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "n_in = 28**2\n",
    "n_out = 10\n",
    "\n",
    "w1 = get_weight(n_in, 50, True)\n",
    "w2 = get_weight(50, n_out, False)\n",
    "b1 = torch.zeros(50)\n",
    "b2 = torch.zeros(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def forward_pass(xb):\n",
    "    xb = lin_rel(xb, w1, b1)\n",
    "    xb = linear(xb, w2, b2)\n",
    "    return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "result = forward_pass(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.2984241247177124\n",
      "Std: 1.1476637125015259\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "get_stats(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "def mse_loss(xb, yb): \n",
    "    \"Mean Square Error loss\"\n",
    "    return (xb.squeeze(-1) - yb).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-9\n",
    "#hide\n",
    "def cross_entropy(xb, targ): \n",
    "    \"Cross Entropy Loss\"\n",
    "    return -( (xb + eps).log()[range(targ.shape[0]), targ.long()].mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    \"Grad for mean squared error\"\n",
    "    inp.g = 2. * (inp.squeeze(-1) - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_grad(inp, out):\n",
    "    \"Grad for ReLU layer\"\n",
    "    inp.g = out.g * (inp > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    \"Grad for linear layer\"\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_grad(inp, targ):\n",
    "    \"Grad for softmax and cross entropy loss\"\n",
    "    targ = torch.nn.functional.one_hot(targ.to(torch.int64), 10)\n",
    "    inp_s = softmax(inp)\n",
    "    inp.g = ( inp_s - targ ) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pass(xb, targ):\n",
    "    l1 = linear(xb, w1, b1)\n",
    "    l1_r = relu(l1)\n",
    "    l2 = linear(l1_r, w2, b2)\n",
    "    \n",
    "    soft = softmax(l2)\n",
    "    \n",
    "    loss = cross_entropy(soft, targ)\n",
    "    \n",
    "    softmax_cross_grad(l2, targ)\n",
    "    lin_grad(l1_r, l2, w2, b2)\n",
    "    rel_grad(l1, l1_r)\n",
    "    lin_grad(xb, l1, w1, b1)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6315)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = full_pass(xt, yt)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig  = xt.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "xt2 = xt.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def auto_full_pass(xb, targ):\n",
    "    l1 = linear(xb, w12, b12)\n",
    "    l1_r = relu(l1)\n",
    "    l2 = linear(l1_r, w22, b22)\n",
    "    soft = softmax(l2)\n",
    "    \n",
    "    loss = cross_entropy(soft, targ)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "loss = auto_full_pass(xt2, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Module():\n",
    "    \"Base class for every layer operation in a sequential network\"\n",
    "    def __call__(self, *args):\n",
    "        \"Executes forward pass of module and stores result in `self.out` for backwards pass\"\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): \n",
    "        \"Executes desired operation of module\"\n",
    "        raise Exception(\"Not Implemented\")\n",
    "        \n",
    "    def backward(self): \n",
    "        \"Calls backwards method to find gradient with stored output of layer\"\n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Linear(Module):\n",
    "    def __init__(self, in_d, out_d, final): \n",
    "        \"Initialize weight using 'get_weight' and bias to 0 for linear operation\"\n",
    "        self.w, self.b = get_weight(in_d, out_d, final), torch.zeros(out_d)\n",
    "\n",
    "    def forward(self, xb): \n",
    "        \"Perform forward linear pass\"\n",
    "        return xb @ self.w + self.b\n",
    "\n",
    "    def bwd(self, out, inp):\n",
    "        \"Gradient with respect to the forward linear layer\"\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReLU(Module):\n",
    "    def forward(self, x): \n",
    "        \"Set all activations to have a minimum of zero, subtract 0.5 to maintain mean of 0\"\n",
    "        return x.clamp_min_(0.)-0.5\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        \"Backward with respect to the ReLU layer\"\n",
    "        inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "eps = 1e-9\n",
    "class CrossSoft(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        \"Calls `soft_forward` and `cross_loss` on inp compared with `targ`\"\n",
    "        softed = self.soft_forward(inp)\n",
    "        return self.cross_loss(softed, targ)\n",
    "    \n",
    "    def soft_forward(self, x): \n",
    "        \"Implements softmax activation function on `x`\"\n",
    "        return torch.exp(x) / torch.sum(torch.exp(x.unsqueeze(-1)), dim=1)\n",
    "        \n",
    "    def cross_loss(self, xb, targ): \n",
    "        \"Cross entropy loss of `xb` compared to `targ`\"\n",
    "        return -( (xb + eps).log()[range(targ.shape[0]), targ.long()].mean() )\n",
    "    \n",
    "    def bwd(self, loss, inp, targ):\n",
    "        \"Gradient with respect to both softmax and cross entropy loss\"\n",
    "        targ = torch.nn.functional.one_hot(targ.to(torch.int64), 10)\n",
    "        inp_s = softmax(inp)\n",
    "        inp.g = ( inp_s - targ ) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "class Model():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.learner = None\n",
    "        for lay in self.layers:\n",
    "            lay.learner = None\n",
    "    \n",
    "    def set_learner(self, learner):\n",
    "        for lay in self.layers:\n",
    "            lay.learner = learner\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Output and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Linear(784,50,True), ReLU(), Linear(50,10, False)]\n",
    "loss_func = CrossSoft()\n",
    "model = Model(layers)\n",
    "loss = loss_func(model(xt),yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func.backward()\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1g = model.layers[0].w.g.clone()\n",
    "w2g = model.layers[2].w.g.clone()\n",
    "b1g = model.layers[0].b.g.clone()\n",
    "b2g = model.layers[2].b.g.clone()\n",
    "ig  = xt.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = xt.clone().requires_grad_(True)\n",
    "model.layers[0].w = model.layers[0].w.clone().requires_grad_(True)\n",
    "model.layers[0].b = model.layers[0].b.clone().requires_grad_(True)\n",
    "model.layers[2].w = model.layers[2].w.clone().requires_grad_(True)\n",
    "model.layers[2].b = model.layers[2].b.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 32 ms, total: 264 ms\n",
      "Wall time: 75.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = loss_func(model(xt), yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 764 ms, sys: 88.2 ms, total: 852 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(w2g, model.layers[2].w.grad)\n",
    "test_near(b2g, model.layers[2].b.grad)\n",
    "test_near(w1g, model.layers[0].w.grad)\n",
    "test_near(b1g, model.layers[0].b.grad)\n",
    "test_near(ig, xt.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
