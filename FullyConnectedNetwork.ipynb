{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp fully_connected_network_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecuturesFromScratch.basic_operations_01 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize(datasets, mean=None, std=None):\n",
    "    if mean is None: mean = datasets.mean()\n",
    "    if std is None: std = datasets.std()\n",
    "        \n",
    "    return (datasets - mean) / std\n",
    "\n",
    "def get_mnist():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    \n",
    "    xt,yt,xv,yv = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "    return normalize(xt).float(), yt.float(), normalize(xv, xt.mean(), xt.std()).float(), yv.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt,yt,xv,yv = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = (yt.max()+1).item()\n",
    "n_in = (xt[0].shape)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def test_near_zero(data, tol=1e-3): assert data.abs() < tol; print(f'Near zero: {data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near zero: 0.00012300178059376776\n"
     ]
    }
   ],
   "source": [
    "test_near_zero(xt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_im(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_stats(data):\n",
    "    print (f'Mean: {data.mean()}')\n",
    "    print (f'Std: {data.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "#Kaiming initialization with fan_in\n",
    "def get_weight(in_d, out_d, final):\n",
    "    if not final: return torch.randn(in_d, out_d) * math.sqrt(2. / in_d)\n",
    "    else: return torch.randn(in_d, out_d) / math.sqrt(in_d)\n",
    "    \n",
    "def linear(x, w, b): return x @ w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def relu(x): return x.clamp_min(0.) - 0.5\n",
    "\n",
    "def lin_rel(x, w, b): return relu(linear(x, w, b))\n",
    "\n",
    "def softmax(x): return torch.exp(x) / torch.sum(torch.exp(x.unsqueeze(-1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 28**2\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = get_weight(n_in, 50, True)\n",
    "w2 = get_weight(50, n_out, False)\n",
    "b1 = torch.zeros(50)\n",
    "b2 = torch.zeros(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(xb):\n",
    "    xb = lin_rel(xb, w1, b1)\n",
    "    xb = linear(xb, w2, b2)\n",
    "    return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forward_pass(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.08484654873609543\n",
      "Std: 0.7059754729270935\n"
     ]
    }
   ],
   "source": [
    "get_stats(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mse_loss(xb, yb): return (xb.squeeze(-1) - yb).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-9\n",
    "def cross_entropy(xb, targ): return -( (xb + eps).log()[range(targ.shape[0]), targ.long()].mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    inp.g = 2. * (inp.squeeze(-1) - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_grad(inp, out):\n",
    "    inp.g = out.g * (inp > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_grad(inp, targ):\n",
    "    targ = torch.nn.functional.one_hot(targ.to(torch.int64), 10)\n",
    "    inp_s = softmax(inp)\n",
    "    inp.g = ( inp_s - targ ) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pass(xb, targ):\n",
    "    l1 = linear(xb, w1, b1)\n",
    "    l1_r = relu(l1)\n",
    "    l2 = linear(l1_r, w2, b2)\n",
    "    \n",
    "    soft = softmax(l2)\n",
    "    \n",
    "    loss = cross_entropy(soft, targ)\n",
    "    \n",
    "    softmax_cross_grad(l2, targ)\n",
    "    lin_grad(l1_r, l2, w2, b2)\n",
    "    rel_grad(l1, l1_r)\n",
    "    lin_grad(xb, l1, w1, b1)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4088)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pass(xt, yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing vs Pytorch Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig  = xt.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = xt.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_full_pass(xb, targ):\n",
    "    l1 = linear(xb, w12, b12)\n",
    "    l1_r = relu(l1)\n",
    "    l2 = linear(l1_r, w22, b22)\n",
    "    soft = softmax(l2)\n",
    "    \n",
    "    loss = cross_entropy(soft, targ)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = auto_full_pass(xt2, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): raise Exception(\"Not Implemented\")\n",
    "        \n",
    "    def backward(self): self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Linear(Module):\n",
    "    def __init__(self, in_d, out_d, final): \n",
    "        self.w, self.b = get_weight(in_d, out_d, final), torch.zeros(out_d)\n",
    "\n",
    "    def forward(self, xb): return xb @ self.w + self.b\n",
    "\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReLU(Module):\n",
    "    def forward(self, x): return x.clamp_min_(0.)-0.5\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CrossSoft(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        softed = self.soft_forward(inp)\n",
    "        return self.cross_loss(softed, targ)\n",
    "    \n",
    "    def soft_forward(self, x): return torch.exp(x) / torch.sum(torch.exp(x.unsqueeze(-1)), dim=1)\n",
    "        \n",
    "    def cross_loss(self, xb, targ): return -( (xb + eps).log()[range(targ.shape[0]), targ.long()].mean() )\n",
    "    \n",
    "    def bwd(self, loss, inp, targ):\n",
    "        targ = torch.nn.functional.one_hot(targ.to(torch.int64), 10)\n",
    "        inp_s = softmax(inp)\n",
    "        inp.g = ( inp_s - targ ) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Model():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self):\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Linear(784,50,True), ReLU(), Linear(50,10, False)]\n",
    "loss_func = CrossSoft()\n",
    "model = Model(layers)\n",
    "loss = loss_func(model(xt),yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func.backward()\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1g = model.layers[0].w.g.clone()\n",
    "w2g = model.layers[2].w.g.clone()\n",
    "b1g = model.layers[0].b.g.clone()\n",
    "b2g = model.layers[2].b.g.clone()\n",
    "ig  = xt.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = xt.clone().requires_grad_(True)\n",
    "model.layers[0].w = model.layers[0].w.clone().requires_grad_(True)\n",
    "model.layers[0].b = model.layers[0].b.clone().requires_grad_(True)\n",
    "model.layers[2].w = model.layers[2].w.clone().requires_grad_(True)\n",
    "model.layers[2].b = model.layers[2].b.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 ms, sys: 24.6 ms, total: 233 ms\n",
      "Wall time: 58 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = loss_func(model(xt), yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 823 ms, sys: 48.8 ms, total: 872 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(w2g, model.layers[2].w.grad)\n",
    "test_near(b2g, model.layers[2].b.grad)\n",
    "test_near(w1g, model.layers[0].w.grad)\n",
    "test_near(b1g, model.layers[0].b.grad)\n",
    "test_near(ig, xt.grad)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LinearLayer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
