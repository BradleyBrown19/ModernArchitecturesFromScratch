{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp convolutions_pooling_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecturesFromScratch.model_training_03 import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions and Pooling\n",
    "> Implementing forwards and backwards passes for convolution and pooling layers as well as support for padding and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.9368033409118652, Loss: 0.19594129920005798\n",
      "Epoch 2, Accuracy: 0.9617834687232971, Loss: 0.13096937537193298\n",
      "Epoch 3, Accuracy: 0.962082028388977, Loss: 0.13402025401592255\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "train, valid = get_datasets()\n",
    "m, o, lf = get_model(0.1)\n",
    "fit(3, m, o, lf, train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Shaping Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Reshape(Module):\n",
    "    \"Module to reshape input tensor into tensor of (bs, `channels`, `size1`, `size2`)\"\n",
    "    def __init__(self, channels, size1, size2):\n",
    "        super().__init__()\n",
    "        self.size1 = size1\n",
    "        self.size2 = size2\n",
    "        self.channels = channels\n",
    "    \n",
    "    def forward(self, xb): return xb.view(-1, self.channels, self.size1, self.size2)\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = out.g.reshape(-1, self.channels*self.size1*self.size2)\n",
    "    \n",
    "    def __repr__(self): return f'Reshape({self.channels}, {self.size1}, {self.size2})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Reshape(Module):\n",
    "    \"Module to reshape input tensor into tensor of (bs, `channels`, `size1`, `size2`)\"\n",
    "    def __init__(self, channels, size1, size2):\n",
    "        super().__init__()\n",
    "        self.size1 = size1\n",
    "        self.size2 = size2\n",
    "        self.channels = channels\n",
    "    \n",
    "    def forward(self, xb): return xb.view(-1, self.channels, self.size1, self.size2)\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = out.g.reshape(-1, self.channels*self.size1*self.size2)\n",
    "    \n",
    "    def __repr__(self): return f'Reshape({self.channels}, {self.size1}, {self.size2})'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Flatten(Module):\n",
    "    \"Module to flatten tensor input into shape (bs, rest)\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.size1 = xb.shape[2]\n",
    "        self.size2 = xb.shape[3]\n",
    "        self.channels = xb.shape[1]\n",
    "        return xb.view(xb.shape[0],-1)\n",
    "    \n",
    "    def bwd(self, out, inp): inp.g = out.g.view(-1, self.channels, self.size1, self.size2)\n",
    "        \n",
    "    def __repr__(self): return f'Flatten()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Flatten(Module):\n",
    "    \"Module to flatten tensor input into shape (bs, rest)\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, xb): \n",
    "        self.size1 = xb.shape[2]\n",
    "        self.size2 = xb.shape[3]\n",
    "        self.channels = xb.shape[1]\n",
    "        return xb.view(xb.shape[0],-1)\n",
    "    \n",
    "    def bwd(self, out, inp): inp.g = out.g.view(-1, self.channels, self.size1, self.size2)\n",
    "        \n",
    "    def __repr__(self): return f'Flatten()'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_fan(dim1, dim2, dim3, dim4, fan_out):\n",
    "    \"Get the appropriate fan value based on the receptive field size and number of activations in the previous layer\"\n",
    "    if dim3 == None and dim4 == None: return dim1\n",
    "    else:\n",
    "        rec_fs = dim3*dim4\n",
    "        return dim2*rec_fs if fan_out else dim1*rec_fs\n",
    "    \n",
    "def get_gain(leak): \n",
    "    \"Get proper initialization gain factor based on the leak amount of the next layer. Leak of 1 if no ReLU after\"\n",
    "    return math.sqrt(2.0 / (1 + leak**2))\n",
    "    \n",
    "def get_weight(dim1, dim2, dim3 = None, dim4 = None, leak=1., fan_out=False):\n",
    "    \"Improved Kaiming initialization to handle convolutional layers. Uses `get_gain` and `get_fan` to get appropriate values\"\n",
    "    fan = get_fan(dim1, dim2, dim3, dim4, fan_out)\n",
    "    gain = get_gain(leak)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    if dim3 == None and dim4 == None: return torch.randn(dim1, dim2) * std\n",
    "    else: return torch.randn(dim1, dim2, dim3, dim4) * std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see: https://arxiv.org/abs/1502.01852 for more details and explanation on Kaiming initialisation. The idea is to regularize the model by keeping the mean and standard deviation close to 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 5, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "test_conv = nn.Conv2d(1, 8, 5)\n",
    "xt, _, _, _ = get_mnist()\n",
    "xt = xt.view(-1, 1, 28, 28)\n",
    "test_conv.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without proper initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.010123089887201786\n",
      "Std: 0.6414140462875366\n"
     ]
    }
   ],
   "source": [
    "get_stats(test_conv(xt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using my own regularization (mean is half due to the ReLU activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5077283382415771\n",
      "Std: 0.7732385993003845\n"
     ]
    }
   ],
   "source": [
    "test_conv.weight = nn.Parameter(get_weight(8, 1, 5, 5, 0, True)) \n",
    "get_stats(relu(test_conv(xt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5470803380012512\n",
      "Std: 1.1031794548034668\n"
     ]
    }
   ],
   "source": [
    "init.kaiming_normal_(test_conv.weight, a=0.)\n",
    "get_stats(relu((test_conv(xt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Padding():\n",
    "    \"Adds padding around an image `size` pixels wide.\"\n",
    "    def __init__(self, size=1, mode=\"constant\", value=0):\n",
    "        self.size, self.mode, self.value = size, mode, value\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        if self.mode == \"constant\": return torch.nn.functional.pad(tensor, [self.size,self.size,self.size,self.size], value=self.value)\n",
    "    \n",
    "    def __repr__(self): return f'Padding (Mode: {self.mode}, Size: {self.size}, Value: {self.value})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can input any of the given modes:<br>\n",
    "`Constant`: Adds a constant pixel of value `value` around the image<br>\n",
    "`Reflection`: Repeats the outer most pixel value of the actual image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convolve(weight, filts, filts_bias, stride=1,padding=None):\n",
    "    \"Performs a convolution on `weight` using the given `filts` and bias `filts_bias`. Can specify a `stride for the convolution or `padding` for the main image.\"\n",
    "    n_filt, depth_f, f_w, f_h = filts.shape\n",
    "    bs, depth_im, im_w, im_h = weight.shape\n",
    "\n",
    "    if padding is not None: \n",
    "        weight = padding(weight)\n",
    "        p_s = padding.size\n",
    "    else: p_s = 0\n",
    "        \n",
    "    _,_,p_w, p_h = weight.shape\n",
    "    \n",
    "    assert depth_f == depth_im\n",
    "\n",
    "    final = torch.zeros(bs, n_filt, int((im_w + 2*p_s - f_w)/stride)+1, int((im_h + 2*p_s - f_h)/stride)+1)\n",
    "    for j in range(0, p_w-f_h+1, stride): #vertical passes\n",
    "        for k in range(0, p_h-f_w+1, stride): #horizontal passes\n",
    "            final[:,:,j//stride,k//stride] = (weight[:,:,j:j+f_h,k:k+f_w].unsqueeze(1)*filts).sum(dim=-1).sum(dim=-1).sum(dim=-1) + filts_bias.unsqueeze(0)\n",
    "                \n",
    "    return final    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def convolve(weight, filts, filts_bias, stride=1,padding=None):\n",
    "    n_filt, depth_f, f_w, f_h = filts.shape\n",
    "    bs, depth_im, im_w, im_h = weight.shape\n",
    "    \n",
    "    if padding is not None: \n",
    "        weight = padding(weight)\n",
    "        p_s = padding.size\n",
    "    else: p_s = 0\n",
    "        \n",
    "    _,_,p_w, p_h = weight.shape\n",
    "    \n",
    "    assert depth_f == depth_im\n",
    "\n",
    "    final = torch.zeros(bs, n_filt, int((im_w + 2*p_s - f_w)/stride)+1, int((im_h + 2*p_s - f_h)/stride)+1)\n",
    "    for j in range(0, p_w-f_h+1, stride): #vertical passes\n",
    "        for k in range(0, p_h-f_w+1, stride): #horizontal passes\n",
    "            final[:,:,j//stride,k//stride] = (weight[:,:,j:j+f_h,k:k+f_w].unsqueeze(1)*filts).sum(dim=-1).sum(dim=-1).sum(dim=-1) + filts_bias.unsqueeze(0)\n",
    "                \n",
    "    return final \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing against PyTorch's convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.randn(10, 16, 28, 28)\n",
    "bs = weight.shape[0]\n",
    "im_h = im_w = weight.shape[2]\n",
    "w_dim = weight.shape[1]\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "pad_amount = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 6, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_dim = 4\n",
    "f_w = 6\n",
    "f_h = f_w\n",
    "test_conv = nn.Conv2d(w_dim, f_dim, f_w, padding=pad_amount, stride=stride)\n",
    "f = test_conv.weight\n",
    "test_conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = test_conv.bias\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 9, 9])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_res = test_conv(weight)\n",
    "pt_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Padding (Mode: constant, Size: 2, Value: 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = Padding(size=pad_amount)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = convolve(weight, f, b, stride, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(res, pt_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_back(out,inp,weight,bias,stride=1,padding=None):\n",
    "    \"Performs a backward pass to get the gradient of the output, `out`, with respect to the `inp`, `weight` of filters and `bias`.\"\n",
    "    dZ = out.g\n",
    "\n",
    "    (A_prev, W, b, stride) = inp, weight.d, bias.d, stride\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_C_prev, n_W_prev, n_H_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (n_C, n_C_prev, f, f) = W.shape\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_C, n_W, n_H) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = torch.zeros((m, n_C_prev, n_W_prev, n_H_prev))                           \n",
    "    dW = torch.zeros((n_C, n_C_prev, f, f))\n",
    "    db = torch.zeros((n_C, 1, 1, 1))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    if padding is not None: \n",
    "        A_prev = padding(A_prev)\n",
    "        dA_prev = padding(dA_prev)\n",
    "        \n",
    "    for h in range(n_H): # loop over vertical axis of the output volume\n",
    "        for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                \n",
    "                # Find the corners of the current \"slice\"\n",
    "                vert_start = h*stride\n",
    "                vert_end = vert_start + f\n",
    "                horiz_start = w*stride\n",
    "                horiz_end = horiz_start + f\n",
    "                    \n",
    "                # Use the corners to define the slice from a_prev_pad\n",
    "                a_slice = A_prev[:, :, horiz_start:horiz_end, vert_start:vert_end]\n",
    "                \n",
    "                ezdz = dZ[:, :, w, h].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "                # Update gradients for the filter, bias and input\n",
    "                dA_prev[:, :, horiz_start:horiz_end, vert_start:vert_end] += (W * ezdz).sum(dim=1)\n",
    "                dW += (a_slice.unsqueeze(1)*ezdz).sum(dim=0)\n",
    "                db += dZ[:, :, w, h].sum(dim=0).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "                \n",
    "    if padding is not None: dA_prev = dA_prev[:, :, padding.size:-padding.size, padding.size:-padding.size]\n",
    "    \n",
    "    weight.update(dW)\n",
    "    bias.update(db.view(-1))\n",
    "    inp.g = dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def conv_back(out,inp,weight,bias,stride=1,padding=None):\n",
    "    \"Performs a backward pass to get the gradient of the output, `out`, with respect to the `inp`, `weight` of filters and `bias`.\"\n",
    "    dZ = out.g\n",
    "\n",
    "    (A_prev, W, b, stride) = inp, weight.d, bias.d, stride\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_C_prev, n_W_prev, n_H_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (n_C, n_C_prev, f, f) = W.shape\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_C, n_W, n_H) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = torch.zeros((m, n_C_prev, n_W_prev, n_H_prev))                           \n",
    "    dW = torch.zeros((n_C, n_C_prev, f, f))\n",
    "    db = torch.zeros((n_C, 1, 1, 1))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    if padding is not None: \n",
    "        A_prev = padding(A_prev)\n",
    "        dA_prev = padding(dA_prev)\n",
    "        \n",
    "    for h in range(n_H): # loop over vertical axis of the output volume\n",
    "        for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                \n",
    "                # Find the corners of the current \"slice\"\n",
    "                vert_start = h*stride\n",
    "                vert_end = vert_start + f\n",
    "                horiz_start = w*stride\n",
    "                horiz_end = horiz_start + f\n",
    "                    \n",
    "                # Use the corners to define the slice from a_prev_pad\n",
    "                a_slice = A_prev[:, :, horiz_start:horiz_end, vert_start:vert_end]\n",
    "                \n",
    "                ezdz = dZ[:, :, w, h].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "                # Update gradients for the filter, bias and input\n",
    "                dA_prev[:, :, horiz_start:horiz_end, vert_start:vert_end] += (W * ezdz).sum(dim=1)\n",
    "                dW += (a_slice.unsqueeze(1)*ezdz).sum(dim=0)\n",
    "                db += dZ[:, :, w, h].sum(dim=0).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "                \n",
    "    if padding is not None: dA_prev = dA_prev[:, :, padding.size:-padding.size, padding.size:-padding.size]\n",
    "    \n",
    "    weight.update(dW)\n",
    "    bias.update(db.view(-1))\n",
    "    inp.g = dA_prev\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Conv(Module):\n",
    "    \"Module to perform convolutions. Can specify kernel size, stride and padding\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, leak=1, padding=None):\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_out = n_in, n_out\n",
    "        self.filters = Parameter(get_weight(n_out, n_in, kernel_size, kernel_size, leak, True))\n",
    "        self.bias = Parameter(torch.zeros(n_out))\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, xb): return convolve(xb, self.filters.d, self.bias.d, self.stride, self.padding)\n",
    "    \n",
    "    def bwd(self, out, inp): conv_back(out, inp, self.filters,self.bias,self.stride,self.padding)\n",
    "        \n",
    "    def __repr__(self): return f'Conv({self.n_in}, {self.n_out}, ks = {self.kernel_size}, stride = {self.stride})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_conv_model(lr):\n",
    "    \"Helper function to get a basic conv model up and running\"\n",
    "    pad1 = Padding(1)\n",
    "    pad2 = Padding(1)\n",
    "    model = SequentialModel(Reshape(1, 28, 28), \n",
    "                            Conv(1, 16, 5, stride=3, leak=0, padding=pad1), \n",
    "                            ReLU(), \n",
    "                            Conv(16, 8, 5, stride=2, leak=1, padding=pad2), \n",
    "                            Flatten(), \n",
    "                            Linear(128, 10, False))\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing vs Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, o, l = get_basic_conv_model(0.1)\n",
    "loss_func = l\n",
    "xt, yt, _, _ = get_mnist()\n",
    "sx, sy = xt[:100], yt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 16, ks = 5, stride = 3)\n",
       "(Layer3): ReLU()\n",
       "(Layer4): Conv(16, 8, ks = 5, stride = 2)\n",
       "(Layer5): Flatten()\n",
       "(Layer6): Linear(128, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx), sy)\n",
    "loss_func.backward()\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxg = sx.g.clone()\n",
    "cw1g = m.layers[1].filters.grad.clone()\n",
    "cb1g = m.layers[1].bias.grad.clone()\n",
    "cw2g = m.layers[3].filters.grad.clone()\n",
    "cb2g = m.layers[3].bias.grad.clone()\n",
    "lw = m.layers[5].w.grad.clone()\n",
    "lb = m.layers[5].b.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx2 = sx.clone().requires_grad_(True)\n",
    "m.layers[1].filters.d.requires_grad_(True)\n",
    "m.layers[1].bias.d.requires_grad_(True)\n",
    "m.layers[3].filters.d.requires_grad_(True)\n",
    "m.layers[3].bias.d.requires_grad_(True)\n",
    "m.layers[5].w.d.requires_grad_(True)\n",
    "m.layers[5].b.d.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx2), sy)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(lb, m.layers[5].b.d.grad)\n",
    "test_near(lw, m.layers[5].w.d.grad)\n",
    "test_near(cb2g, m.layers[3].bias.d.grad)\n",
    "test_near(cw2g, m.layers[3].filters.d.grad)\n",
    "test_near(cb1g, m.layers[1].bias.d.grad)\n",
    "test_near(cw1g, m.layers[1].filters.d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "\n",
    "def get_linear_model(lr):\n",
    "    model = SequentialModel(Linear(784, 50, True), ReLU(), Linear(50, 10, False))\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func\n",
    "\n",
    "def get_model(lr, modules):\n",
    "    model = SequentialModel(*modules)\n",
    "    loss_func = CrossEntropy()\n",
    "    optimizer = Optimizer(model.parameters(), lr)\n",
    "    return model, optimizer, loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [Reshape(1, 28, 28), \n",
    "     Conv(1, 4, 5, stride=1, leak=0), \n",
    "     ReLU(), \n",
    "     Conv(4, 1, 5, stride=1, leak=1), \n",
    "     Flatten(), \n",
    "     Linear(20*20, 10, False)]\n",
    "\n",
    "m, o, l = get_model(0.1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_small_datasets():\n",
    "    \"Helper function to get smaller versions of MNIST datasets\"\n",
    "    xt, yt, xv, yv = get_mnist()\n",
    "    tr = Dataset(xt[:500], yt[:500])\n",
    "    val = Dataset(xv[:100], yv[:100])\n",
    "    train = DataLoader(tr, Batcher(tr, 64, True), collate)\n",
    "    valid = DataLoader(val, Batcher(val, 64, False), collate)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid = get_small_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.0963541716337204, Loss: nan\n",
      "Epoch 2, Accuracy: 0.0963541716337204, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "fit(2, m, o, l, train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def max_pool(inp): \n",
    "    \"Applies a max pooling operation on `inp`\"\n",
    "    return inp.max(dim=-1).values.max(dim=-1).values\n",
    "\n",
    "def avg_pool(inp): \n",
    "    \"Applies an average pooling operation on `inp`\"\n",
    "    return torch.mean(inp,dim=(2,3))\n",
    "\n",
    "def pool(inp, ks, stride, padding=None, operation=max_pool):\n",
    "    \"Runs a pooling operation on `inp` of type `operation` with given `stride`, `ks` and `padding`\"\n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inpp = padding(inp)\n",
    "    else: inpp = inp\n",
    "        \n",
    "    bs, nc, h, w = inp.shape\n",
    "    nw, nh = int((int(w - ks) / stride)+1), int((int(h - ks) / stride)+1)\n",
    "    \n",
    "    out = torch.zeros(bs, nc, nw, nh)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            window = inpp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "            out[:,:,j,i] = operation(window)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def pool(inp, ks, stride, padding=None, operation=max_pool):\n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inpp = padding(inp)\n",
    "    else: inpp = inp\n",
    "        \n",
    "    bs, nc, h, w = inp.shape\n",
    "    nw, nh = int((int(w - ks) / stride)+1), int((int(h - ks) / stride)+1)\n",
    "    \n",
    "    out = torch.zeros(bs, nc, nw, nh)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            window = inpp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "            out[:,:,j,i] = operation(window)\n",
    "    \n",
    "    return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Pooling Forward Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = torch.randn(16, 3, 28, 28)\n",
    "ks = 3\n",
    "stride = 1\n",
    "pad_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_max = nn.MaxPool2d(ks, stride=stride, padding=pad_size)\n",
    "py_avg = nn.AvgPool2d(ks, stride=stride, padding=pad_size)\n",
    "py_max_result = py_max(test_t)\n",
    "py_avg_result = py_avg(test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = Padding(size=pad_size) if pad_size > 0 else None\n",
    "my_avg = pool(test_t, ks, stride, pad, avg_pool)\n",
    "my_max = pool(test_t, ks, stride, pad, max_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "test_near(py_max_result, my_max)\n",
    "test_near(py_avg_result, my_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def max_back(window): \n",
    "    \"Gradient for `window` of max pooling\"\n",
    "    A = torch.zeros(window.shape)\n",
    "    bs, nc, _, _ = window.shape\n",
    "    \n",
    "    for i in range(bs):\n",
    "        for j in range(nc):\n",
    "            A[i,j,:,:] = window[i,j,:,:] == window[i,j,:,:].max()\n",
    "    \n",
    "    return A\n",
    "    \n",
    "    \n",
    "def average_back(window, shape):\n",
    "    \"Gradient for `window` of average pooling\"\n",
    "    height, width = shape\n",
    "    window_sum = window.unsqueeze(-1).unsqueeze(-1) / height*width\n",
    "    return torch.ones(shape).unsqueeze(0).unsqueeze(0) * window_sum\n",
    "\n",
    "def pool_back(out, inp, ks, stride, padding=None, operation=max_pool):\n",
    "    \"Function to pass gradient through pooling layers\"\n",
    "    dZ = out.g\n",
    "    \n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inp = padding(inp)\n",
    "        \n",
    "    bs, nc, nh, nw = dZ.shape\n",
    "\n",
    "    dA_prev = torch.zeros(inp.shape)\n",
    "    \n",
    "    shape = (ks,ks)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            \n",
    "            if operation == max_pool:\n",
    "                window = inp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "                \n",
    "                mask = max_back(window)\n",
    "                \n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += mask*dZ[:,:,j,i].unsqueeze(-1).unsqueeze(-1)\n",
    "            \n",
    "            elif operation == avg_pool:\n",
    "                dz = dZ[:,:,j, i]\n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += average_back(dz, shape)\n",
    "    \n",
    "    inp.g = dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def pool_back(out, inp, ks, stride, padding=None, operation=max_pool):\n",
    "    dZ = out.g\n",
    "    \n",
    "    if padding is not None: \n",
    "        if operation == max_pool: padding.value = inp.min() - 1\n",
    "        inp = padding(inp)\n",
    "        \n",
    "    bs, nc, nh, nw = dZ.shape\n",
    "\n",
    "    dA_prev = torch.zeros(inp.shape)\n",
    "    \n",
    "    shape = (ks,ks)\n",
    "    \n",
    "    for i in range(nh):\n",
    "        for j in range(nw):\n",
    "            \n",
    "            if operation == max_pool:\n",
    "                window = inp[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks]\n",
    "                \n",
    "                mask = max_back(window)\n",
    "                \n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += mask*dZ[:,:,j,i].unsqueeze(-1).unsqueeze(-1)\n",
    "            \n",
    "            elif operation == avg_pool:\n",
    "                dz = dZ[:,:,j, i]\n",
    "                dA_prev[:,:,j*stride:j*stride+ks, i*stride:i*stride+ks] += average_back(dz, shape)\n",
    "    \n",
    "    inp.g = dA_prev\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pool(Module):\n",
    "    \"Module for defining a pooling layer in a model\"\n",
    "    def __init__(self, operation, ks=2, stride=2, padding=None):\n",
    "        super().__init__()\n",
    "        self.ks, self.stride, self.padding, self.operation = ks, stride, padding, operation\n",
    "    \n",
    "    def forward(self, xb): return pool(xb, self.ks, self.stride, self.padding, operation=self.operation)\n",
    "    \n",
    "    def bwd(self, out, inp): return pool_back(out, inp, self.ks, self.stride, self.padding, operation=self.operation)\n",
    "    \n",
    "    def __repr__(self): \n",
    "        if self.operation == max_pool: ptype = \"Max\"\n",
    "        elif self.operation == avg_pool: ptype = \"Average\"\n",
    "        else: ptype = \"Custom\"\n",
    "        return f'{ptype}Pool(ks: {self.ks}, stride: {self.stride})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Reshape(1, 28, 28),\n",
    "          Conv(1, 4),\n",
    "          Pool(avg_pool, ks=2, stride=1),\n",
    "          Conv(4, 1),\n",
    "          Flatten(),\n",
    "          Linear(529, 10, False)]\n",
    "m, o, l = get_model(0.1, layers)\n",
    "train,valid = get_small_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Layer1): Reshape(1, 28, 28)\n",
       "(Layer2): Conv(1, 4, ks = 3, stride = 1)\n",
       "(Layer3): AveragePool(ks: 2, stride: 1)\n",
       "(Layer4): Conv(4, 1, ks = 3, stride = 1)\n",
       "(Layer5): Flatten()\n",
       "(Layer6): Linear(529, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(m(sx), sy)\n",
    "loss_func.backward()\n",
    "m.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxg = sx.g.clone()\n",
    "cw = m.layers[1].filters.grad.clone()\n",
    "cb = m.layers[1].bias.grad.clone()\n",
    "lw = m.layers[5].w.grad.clone()\n",
    "lb = m.layers[5].b.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx2 = sx.clone().requires_grad_(True)\n",
    "m.layers[1].filters.d.requires_grad_(True)\n",
    "m.layers[1].bias.d.requires_grad_(True)\n",
    "m.layers[5].w.d.requires_grad_(True)\n",
    "m.layers[5].b.d.requires_grad_(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
