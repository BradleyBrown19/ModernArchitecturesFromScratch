# AUTOGENERATED! DO NOT EDIT! File to edit: SingleShotDetector.ipynb (unless otherwise specified).

__all__ = ['hw_bb', 'bb_hw', 'show_img', 'draw_outline', 'draw_rect', 'draw_text', 'draw_im', 'draw_idx',
           'get_res_body', 'StandardConv', 'PredictionConv', 'SSDHead', 'GenericModel']

# Cell
from nbdev.showdoc import show_doc
from ModernArchitecturesFromPyTorch.nb_XResNet import *
from pathlib import Path
import json
from PIL import ImageDraw, ImageFont
from matplotlib import patches, patheffects
from fastai.vision.data import open_image

# Cell
def hw_bb(bb):
    "Convert height width to bounding box coords"
    return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])

def bb_hw(a):
    "Convert bounding box coords to height width"
    return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])

# Cell
def show_img(im, figsize=None, ax=None):
    "Show the given image"
    im = image2np(im.data)
    if not ax: fig,ax = plt.subplots(figsize=figsize)
    ax.imshow(im)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    return ax

# Cell
def draw_outline(o, lw):
    "Draw the outline around a bounding box"
    o.set_path_effects([patheffects.Stroke(
        linewidth=lw, foreground='black'), patheffects.Normal()])

# Cell
def draw_rect(ax, b):
    "Add a square capturing a given bounding box"
    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))
    draw_outline(patch, 4)

# Cell
def draw_text(ax, xy, txt, sz=14):
    "Draw the class type aboce the bounding box of font size `sz`"
    text = ax.text(*xy, txt,
        verticalalignment='top', color='white', fontsize=sz, weight='bold')
    draw_outline(text, 1)

# Cell
def draw_im(im, ann):
    "Draw an image along with it's bounding box and class"
    ax = show_img(im, figsize=(16,8))
    for b,c in ann:
        b = bb_hw(b)
        draw_rect(ax, b)
        draw_text(ax, b[:2], cats[c], sz=16)

# Cell
def draw_idx(i):
    "Open and draw a given image with id `i`"
    im_a = trn_anno[i]
    im = open_image(jpgs/trn_fns[i])
    print(im.shape)
    draw_im(im, im_a)

# Cell
def get_res_body(size, n_in, c_out=10):
    "Return the body of a resnet with given `size` and `n_in` input channels"
    return getResnet(size, n_in, c_out).resnet[:-3]

# Cell
class StandardConv(nn.Module):
    "Standard convolutional layer to downsample the ResNet output"
    def __init__(self, n_in, n_out, ks=3, stride=2, drop=0.1, **kwargs):
        super().__init__()
        layers = [ConvBatchLayer(n_in, n_out, kernel_size=ks, **kwargs)]
        if drop > 0: layers.append(nn.Dropout(drop))
        self.layers = nn.Sequential(*layers)

    def forward(self, xb): return self.layers(xb)

# Cell
class PredictionConv(nn.Module):
    "Convolutional layer to split activations into predicted bbox coordinates and classes"
    def __init__(self, k, n_in, n_clas):
        super().__init__()
        self.k = k
        self.class_conv = AutoConv(n_in, n_clas+1, kernel_size=3)
        self.bbox_conv = AutoConv(n_in, 4, kernel_size=3)

    def flatten_conv(self, xb, k):
        bs,n_c,gx,gy = xb.size()
        xb = xb.permute(0,2,3,1).contiguous
        xb = xb.view(bs, -1, n_c//k)
        return xb

    def forward(self, xb):
        return [self.flatten_conv(self.class_conv(xb), self.k),
                self.flatten_conv(self.bbox_conv(xb), self.k)]


# Cell
class SSDHead(nn.Module):
    "Convolutional layers to split resnet body activations into predictions of various sizes. Each representing different regions of the image"
    def __init__(self, k, n_clas, drop=0.1):
        super().__init__()
        self.relu = nn.ReLU()
        self.drop = nn.Dropout(drop)
        self.initial_layer = StandardConv(512, 256, stride=1)
        self.conv_to_4 = StandardConv(256, 256)
        self.conv_to_2 = StandardConv(256, 256)
        self.conv_to_1 = StandardConv(256, 256)

        self.out_conv_4 = PredictionConv(k, 256, n_clas)
        self.out_conv_2 = PredictionConv(k, 256, n_clas)
        self.out_conv_1 = PredictionConv(k, 256, n_clas)

    def forward(self, xb):
        xb = self.initial_layer(xb)

        xb_4 = self.conv_to_4(xb)
        xb_4_clas, xb_4_bbox = self.out_conv_4(xb_4)

        xb_2 = self.conv_to_4(xb_4)
        xb_2_clas, xb_2_bbox = self.out_conv_4(xb_2)

        xb_1 = self.conv_to_4(xb_2)
        xb_1_clas, xb_1_bbox = self.out_conv_4(xb_1)

        return [torch.cat([xb_4_clas, xb_2_clas, xb_1_clas], dim=1),
                torch.cat([xb_4_bbox, xb_2_bbox, xb_1_bbox], dim=1)]

# Cell
class GenericModel(nn.Module):
    "Wrapper to combine a head and body into a single model"
    def __init__(self, body, head):
        super().__init__()
        self.body = body
        self.head = head

    def forward(self, xb): return self.head(self.body(xb))