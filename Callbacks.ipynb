{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callbacks_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ModernArchitecturesFromScratch.basic_operations_01 import *\n",
    "from ModernArchitecturesFromScratch.fully_connected_network_02 import *\n",
    "from ModernArchitecturesFromScratch.model_training_03 import *\n",
    "from ModernArchitecturesFromScratch.convolutions_pooling_04 import *\n",
    "from nbdev.showdoc import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __repr__(self): return f'X: {self.x.shape}, Y: {self.y.shape}'\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, batcher, collate_fcn): self.ds, self.batcher, self.collate_fcn = ds, batcher, collate_fcn    \n",
    "    def __iter__(self):\n",
    "        for b in self.batcher: yield self.collate_fcn([self.ds[i] for i in b])     \n",
    "    @property\n",
    "    def dataset(self): return self.ds\n",
    "    def __len__(self): return math.ceil(len(self.ds) / self.batcher.bs)\n",
    "    def __repr__(self): return f'Data: {self.ds}, bs = {self.batcher.bs}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Databunch():\n",
    "    \"Wrapper to combine training and validation datasets\"\n",
    "    def __init__(self, train_dl, valid_dl): self.train, self.valid = train_dl, valid_dl\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self): return self.train.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid.dataset\n",
    "    \n",
    "    def __repr__(self): return f'Databunch(\\nTrain: {self.train}, \\nValid{self.valid}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_databunch(xt, yt, xv, yv, bs=64):\n",
    "    \"Helper function to get a databunch of given `bs`\"\n",
    "    t_data, v_data = Dataset(xt, yt), Dataset(xv, yv)\n",
    "    t_dl, v_dl = DataLoader(t_data, Batcher(t_data, bs, True), collate), DataLoader(t_data, Batcher(t_data, bs*2, False), collate)\n",
    "    return Databunch(t_dl, v_dl)\n",
    "\n",
    "def get_mnist_databunch():\n",
    "    \"Grabs MNIST databuunch usuing `get_mnist` and `get_databunch`\"\n",
    "    return get_databunch(*get_mnist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_mnist_databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databunch(\n",
       "Train: Data: X: torch.Size([50000, 784]), Y: torch.Size([50000]), bs = 64, \n",
       "ValidData: X: torch.Size([50000, 784]), Y: torch.Size([50000]), bs = 128\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, loss_func, optimizer, db):\n",
    "        \"Wrapper for model, loss function, optimizer and databunch\"\n",
    "        self.model, self.loss_func, self.optimizer, self.db = model, loss_func, optimizer, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    \"All encompossing class to train a model with specific callbacks\"\n",
    "    def __init__(self, learner, cbs=None):\n",
    "        cbs = [] if cbs is None else cbs\n",
    "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
    "        \n",
    "        for cb in self.cbs:\n",
    "            cb.runner = self\n",
    "            \n",
    "        self.learner = learner\n",
    "    \n",
    "    @property\n",
    "    def model(self): return self.learner.model\n",
    "    @property\n",
    "    def optimizer(self): return self.learner.optimizer\n",
    "    @property\n",
    "    def loss_func(self): return self.learner.loss_func\n",
    "    @property\n",
    "    def databunch(self): return self.learner.db\n",
    "    \n",
    "    def do_one_batch(self, xb, yb):\n",
    "        \"Applies forward and backward passes of model to one batch\"\n",
    "        self.xb, self.yb = xb, yb\n",
    "        \n",
    "        self.pred = self.learner.model(xb)\n",
    "        self.loss = self.learner.loss_func(self.pred, yb)\n",
    "        if self.check_callbacks('after_loss') or not self.learner.model.training: return\n",
    "        \n",
    "        self.learner.loss_func.backward()\n",
    "        if self.check_callbacks('after_loss_back'): return\n",
    "        \n",
    "        self.learner.model.backward()\n",
    "        if self.check_callbacks('after_model_back'): return\n",
    "        \n",
    "        self.opt.step()\n",
    "        if self.check_callbacks('after_opt'): return\n",
    "        \n",
    "        self.opt.zero_grad()\n",
    "        if self.check_callbacks('after_zero_grad'): return\n",
    "    \n",
    "    def do_all_batches(self, dl):\n",
    "        \"Runs every batch of a dataloader through `do_one_batch`\"\n",
    "        self.iters, self.iters_done = len(dl), 0\n",
    "        for xb, yb in dl:\n",
    "            if self.stop: break\n",
    "            if self.check_callbacks('before_batch'): return\n",
    "            self.do_one_batch(xb,yb)\n",
    "            if self.check_callbacks('after_batch'): return\n",
    "        self.iters = 0\n",
    "            \n",
    "        self.stop = False\n",
    "\n",
    "    def fit(self, epochs, lr=0.1):\n",
    "        \"Method to fit the model `epoch` times using learning rate `lr`\"\n",
    "        self.lr, self.epochs = lr, epochs\n",
    "        if self.check_callbacks('before_fit'): return\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.epoch = epoch\n",
    "            if self.check_callbacks('before_epoch'): return\n",
    "            if not self.check_callbacks('before_train'): self.do_all_batches(self.learner.db.train)\n",
    "            if not self.check_callbacks('before_valid'): self.do_all_batches(self.learner.db.valid)\n",
    "            if self.check_callbacks('after_epoch'): break\n",
    "        \n",
    "        if self.check_callbacks('after_fit'): return\n",
    "    \n",
    "    def check_callbacks(self, state):\n",
    "        \"Helper functions to run through each callback, calling it's state method if applicable\"\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, state, None)\n",
    "            if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Runner.__init__\" class=\"doc_header\"><code>Runner.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Runner.__init__</code>(**`learner`**, **`cbs`**=*`None`*)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Runner.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Runner.do_one_batch\" class=\"doc_header\"><code>Runner.do_one_batch</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Runner.do_one_batch</code>(**`xb`**, **`yb`**)\n",
       "\n",
       "Applies forward and backward passes of model to one batch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Runner.do_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Runner.do_all_batches\" class=\"doc_header\"><code>Runner.do_all_batches</code><a href=\"__main__.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Runner.do_all_batches</code>(**`dl`**)\n",
       "\n",
       "Runs every batch of a dataloader through `do_one_batch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Runner.do_all_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Runner.fit\" class=\"doc_header\"><code>Runner.fit</code><a href=\"__main__.py#L54\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Runner.fit</code>(**`epochs`**, **`lr`**=*`0.1`*)\n",
       "\n",
       "Method to fit the model `epoch` times using learning rate `lr`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Runner.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Runner.check_callbacks\" class=\"doc_header\"><code>Runner.check_callbacks</code><a href=\"__main__.py#L68\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Runner.check_callbacks</code>(**`state`**)\n",
       "\n",
       "Helper functions to run through each callback, calling it's state method if applicable"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Runner.check_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callback():\n",
    "    \"Base class for callbacks, defines order of execution and allows abstraction of self to runner class\"\n",
    "    _order = 0\n",
    "    def __getattr__(self,k):\n",
    "        #If callback doesn't have an attribute, check the runner\n",
    "        return getattr(self.runner, k)\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    \"Keeps track of training/eval mode of model and progress through training\"\n",
    "    _order = 10\n",
    "    \n",
    "    def before_fit(self):\n",
    "        self.runner.opt = self.learner.optimizer(self.learner.model.parameters(), self.lr)\n",
    "        self.runner.epochs_done = 0.\n",
    "        \n",
    "    def before_batch(self):\n",
    "        self.runner.iters_done += 1\n",
    "        self.runner.epochs_done += 1/self.iters\n",
    "        \n",
    "    def before_valid(self):\n",
    "        self.model.training = False\n",
    "    \n",
    "    def before_train(self):\n",
    "        self.model.training = True\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        self.runner.iters_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Stat():\n",
    "    \"Defines a metric to keep track of through training, metric calculated using `calc`\"\n",
    "    def __init__(self, calc): self.calc, self.value, self.count = calc, 0., 0\n",
    "    \n",
    "    def __call__(self, bs, *args):\n",
    "        self.value += self.calc(*args) * bs\n",
    "        self.count += bs\n",
    "    \n",
    "    def reset(self): self.value, self.count = 0., 0\n",
    "        \n",
    "    def __repr__(self): return f'{(self.calc.__name__).capitalize()}: {self.value / self.count}' if self.count > 0 else f'{(self.calc.__name__).capitalize()}'\n",
    "    \n",
    "class StatTracker():\n",
    "    \"Class to implement thet `Stats` callback using metrics of class `Stat`\"\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.in_train = in_train\n",
    "        self.metrics = [Stat(m) for m in metrics]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.count, self.tot_loss = 0., 0.\n",
    "        for met in self.metrics: met.reset()\n",
    "    \n",
    "    def __len__(self): return len(self.metrics)\n",
    "    \n",
    "    def accumulate(self, run):\n",
    "        \"Scales the metric value by the amount of data in each batch\"\n",
    "        bs = run.xb.shape[0]\n",
    "        self.tot_loss = run.loss * bs\n",
    "        self.count += bs\n",
    "        for i,met in enumerate(self.metrics):\n",
    "            met(bs, run.pred, run.yb)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.count < 1: return \"\"\n",
    "        else:\n",
    "            printed_stats = f'Loss: {self.tot_loss / self.count}'\n",
    "            for met in self.metrics:\n",
    "                printed_stats += f', {met}'\n",
    "            return f'{\"Train\" if self.in_train else \"Valid\"}: {printed_stats}'\n",
    "    \n",
    "class Stats(Callback):\n",
    "    \"Callback to keep track of `metrics`\"\n",
    "    def __init__(self, metrics):\n",
    "        self.train, self.valid = StatTracker(metrics, True), StatTracker(metrics, False)\n",
    "    \n",
    "    def before_epoch(self):\n",
    "        self.train.reset()\n",
    "        self.valid.reset()\n",
    "    \n",
    "    def after_loss(self):\n",
    "        stats = self.train if self.model.training else self.valid\n",
    "        stats.accumulate(self.runner)\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        print(f'Epoch: {self.epoch+1}')\n",
    "        print(self.train)\n",
    "        print(self.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(learn, [Stats([accuracy])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train: Loss: 0.00012180877820355818, Accuracy: 0.9136000275611877\n",
      "Valid: Loss: 0.0002788938581943512, Accuracy: 0.9381999969482422\n",
      "Epoch: 2\n",
      "Train: Loss: 4.875722515862435e-05, Accuracy: 0.9558600187301636\n",
      "Valid: Loss: 0.00014287835801951587, Accuracy: 0.9671800136566162\n",
      "Epoch: 3\n",
      "Train: Loss: 0.00010866371303563938, Accuracy: 0.966920018196106\n",
      "Valid: Loss: 0.00022182443353813142, Accuracy: 0.9489399790763855\n",
      "Epoch: 4\n",
      "Train: Loss: 5.4490061302203685e-05, Accuracy: 0.9728999733924866\n",
      "Valid: Loss: 7.179772364906967e-05, Accuracy: 0.9632599949836731\n",
      "Epoch: 5\n",
      "Train: Loss: 4.08835694543086e-05, Accuracy: 0.9775000214576721\n",
      "Valid: Loss: 8.388313290197402e-05, Accuracy: 0.9725599884986877\n"
     ]
    }
   ],
   "source": [
    "run.fit(5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
